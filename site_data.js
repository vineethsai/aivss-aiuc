window.CROSSWALK_DATA = {
  "meta": {
    "generated_at": "2026-02-26T00:00:00",
    "aiuc_workbook": "AIUC-AIVSS Reviewed Crosswalk.xlsx",
    "aivss_doc": "AIVSS Scoring System For OWASP Agentic AI Core Security Risks v0.5",
    "asi_doc": "OWASP Top 10 For Agentic Applications 2026 (Dec 2025)",
    "mapping_version": "v6 (AIUC team reviewed crosswalk applied)",
    "scope_notes": "AIUC-1 (Jan 2026) focuses on single-agent AI systems. Multi-agent orchestration scenarios are not explicitly covered in the current AIUC scope. Agent Identity Impersonation now has 2 requirements mapped via AIUC review.",
    "coverage_gaps": [
      "Agent Orchestration & Multi-Agent Exploitation"
    ]
  },
  "aivss_core_risks": [
    "Agentic AI Tool Misuse",
    "Agent Access Control Violation",
    "Agent Cascading Failures",
    "Agent Orchestration & Multi-Agent Exploitation",
    "Agent Identity Impersonation",
    "Agent Memory & Context Manipulation",
    "Insecure Agent Critical Systems Interaction",
    "Agent Supply Chain & Dependency Risk",
    "Agent Untraceability",
    "Agent Goal & Instruction Manipulation"
  ],
  "asi_bridge": [
    {
      "ASI_ID": "ASI01",
      "ASI_Title": "Agent Goal Hijack",
      "AIVSS_Primary": "Agent Goal & Instruction Manipulation"
    },
    {
      "ASI_ID": "ASI02",
      "ASI_Title": "Tool Misuse & Exploitation",
      "AIVSS_Primary": "Agentic AI Tool Misuse"
    },
    {
      "ASI_ID": "ASI03",
      "ASI_Title": "Identity & Privilege Abuse",
      "AIVSS_Primary": "Agent Access Control Violation"
    },
    {
      "ASI_ID": "ASI04",
      "ASI_Title": "Agentic Supply Chain Vulnerabilities",
      "AIVSS_Primary": "Agent Supply Chain & Dependency Risk"
    },
    {
      "ASI_ID": "ASI05",
      "ASI_Title": "Unexpected Code Execution (RCE)",
      "AIVSS_Primary": "Insecure Agent Critical Systems Interaction"
    },
    {
      "ASI_ID": "ASI06",
      "ASI_Title": "Memory & Context Poisoning",
      "AIVSS_Primary": "Agent Memory & Context Manipulation"
    },
    {
      "ASI_ID": "ASI07",
      "ASI_Title": "Insecure Inter-Agent Communication",
      "AIVSS_Primary": "Agent Memory & Context Manipulation"
    },
    {
      "ASI_ID": "ASI08",
      "ASI_Title": "Cascading Failures",
      "AIVSS_Primary": "Agent Cascading Failures"
    },
    {
      "ASI_ID": "ASI09",
      "ASI_Title": "Human-Agent Trust Exploitation",
      "AIVSS_Primary": "Agent Untraceability"
    },
    {
      "ASI_ID": "ASI10",
      "ASI_Title": "Rogue Agents",
      "AIVSS_Primary": "Agent Goal & Instruction Manipulation"
    }
  ],
  "summary": [
    {
      "AIVSS Core Risk": "Agentic AI Tool Misuse",
      "Requirements (count)": 3,
      "Controls/Evidence (count)": 8
    },
    {
      "AIVSS Core Risk": "Agent Access Control Violation",
      "Requirements (count)": 5,
      "Controls/Evidence (count)": 18
    },
    {
      "AIVSS Core Risk": "Agent Cascading Failures",
      "Requirements (count)": 6,
      "Controls/Evidence (count)": 5
    },
    {
      "AIVSS Core Risk": "Agent Orchestration & Multi-Agent Exploitation",
      "Requirements (count)": 0,
      "Controls/Evidence (count)": 0
    },
    {
      "AIVSS Core Risk": "Agent Identity Impersonation",
      "Requirements (count)": 2,
      "Controls/Evidence (count)": 0
    },
    {
      "AIVSS Core Risk": "Agent Memory & Context Manipulation",
      "Requirements (count)": 3,
      "Controls/Evidence (count)": 2
    },
    {
      "AIVSS Core Risk": "Insecure Agent Critical Systems Interaction",
      "Requirements (count)": 3,
      "Controls/Evidence (count)": 3
    },
    {
      "AIVSS Core Risk": "Agent Supply Chain & Dependency Risk",
      "Requirements (count)": 7,
      "Controls/Evidence (count)": 14
    },
    {
      "AIVSS Core Risk": "Agent Untraceability",
      "Requirements (count)": 12,
      "Controls/Evidence (count)": 61
    },
    {
      "AIVSS Core Risk": "Agent Goal & Instruction Manipulation",
      "Requirements (count)": 10,
      "Controls/Evidence (count)": 18
    }
  ],
  "requirements": [
    {
      "RequirementID": "A001",
      "Principle": "Data & Privacy",
      "RequirementTitle": "A001: Establish input data policy",
      "FullRequirement": "Establish and communicate AI input data policies covering how customer data is used for model training, inference processing, data retention periods, and customer data rights",
      "Application": "Mandatory",
      "Frequency": "Every 12 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Memory & Context Manipulation",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Input data policies govern how data enters agent memory and context, directly addressing manipulation risks. Policies also support audit.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 1.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "A002",
      "Principle": "Data & Privacy",
      "RequirementTitle": "A002: Establish output data policy",
      "FullRequirement": "Establish AI output ownership, usage, opt-out and deletion policies to customers and communicate these policies",
      "Application": "Mandatory",
      "Frequency": "Every 12 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Output data policies establish ownership and accountability for AI-generated content, directly supporting traceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "A003",
      "Principle": "Data & Privacy",
      "RequirementTitle": "A003: Limit AI agent data collection",
      "FullRequirement": "Implement safeguards to limit AI agent data access to task-relevant information based on user roles and context",
      "Application": "Mandatory",
      "Frequency": "Every 12 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Access Control Violation",
      "AIVSS_Secondary": null,
      "ASI_ID": "ASI06",
      "ASI_Title": "Memory & Context Poisoning",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Detected cues: context. ASI label inferred: ASI06 (Memory & Context Poisoning). Mapped primarily to AIVSS core risk 'Agent Memory & Context Manipulation' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.5, \"toolUse\": 0.0, \"memoryUse\": 1.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "A004",
      "Principle": "Data & Privacy",
      "RequirementTitle": "A004: Protect IP & trade secrets",
      "FullRequirement": "Implement safeguards or technical controls to prevent AI systems from leaking company intellectual property or confidential information",
      "Application": "Mandatory",
      "Frequency": "Every 12 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Insecure Agent Critical Systems Interaction",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Mapped primarily to AIVSS core risk 'Agent Access Control Violation' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "A005",
      "Principle": "Data & Privacy",
      "RequirementTitle": "A005: Prevent cross-customer data exposure",
      "FullRequirement": "Implement safeguards to prevent cross-customer data exposure when combining customer data from multiple sources",
      "Application": "Mandatory",
      "Frequency": "Every 12 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Access Control Violation",
      "AIVSS_Secondary": "Agent Memory & Context Manipulation",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: cross-customer, rce. Mapped primarily to AIVSS core risk 'Agent Access Control Violation' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Memory & Context Manipulation.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "A006",
      "Principle": "Data & Privacy",
      "RequirementTitle": "A006: Prevent PII leakage",
      "FullRequirement": "Establish safeguards to prevent personal data leakage through AI outputs",
      "Application": "Mandatory",
      "Frequency": "Every 12 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Access Control Violation",
      "AIVSS_Secondary": "Agent Memory & Context Manipulation",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "PII guardrails enforce data access boundaries, preventing unauthorized access to sensitive information.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "A007",
      "Principle": "Data & Privacy",
      "RequirementTitle": "A007: Prevent IP violations",
      "FullRequirement": "Implement safeguards and technical controls to prevent AI outputs from violating copyrights, trademarks, or other third-party intellectual property rights",
      "Application": "Mandatory",
      "Frequency": "Every 12 months",
      "Capabilities": "Text-generation, Voice-generation, Image-generation",
      "AIVSS_Primary": "Agent Supply Chain & Dependency Risk",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": "ASI04",
      "ASI_Title": "Agentic Supply Chain Vulnerabilities",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "IP violation prevention addresses risks from training data and model dependencies containing copyrighted content. Content provenance tracking supports traceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "B001",
      "Principle": "Security",
      "RequirementTitle": "B001: Third-party testing of adversarial robustness",
      "FullRequirement": "Implement adversarial testing program to validate system resilience against adversarial inputs and prompt injection attempts in line with adversarial threat taxonomy",
      "Application": "Mandatory",
      "Frequency": "Every 3 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Goal & Instruction Manipulation",
      "AIVSS_Secondary": "Agent Cascading Failures",
      "ASI_ID": "ASI01",
      "ASI_Title": "Agent Goal Hijack",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Adversarial testing validates resilience against prompt injection and goal hijacking attacks. Testing records support traceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "B002",
      "Principle": "Security",
      "RequirementTitle": "B002: Detect adversarial input",
      "FullRequirement": "Implement monitoring capabilities to detect and respond to adversarial inputs and prompt injection attempts",
      "Application": "Optional",
      "Frequency": "Every 3 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Goal & Instruction Manipulation",
      "AIVSS_Secondary": null,
      "ASI_ID": "ASI01",
      "ASI_Title": "Agent Goal Hijack",
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: prompt injection. ASI label inferred: ASI01 (Agent Goal Hijack). Mapped primarily to AIVSS core risk 'Agent Goal & Instruction Manipulation' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "B003",
      "Principle": "Security",
      "RequirementTitle": "B003: Manage public release of technical details",
      "FullRequirement": "Implement controls to prevent over-disclosure of technical information about AI systems and organizational details that could enable adversarial targeting",
      "Application": "Optional",
      "Frequency": "Every 12 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Supply Chain & Dependency Risk",
      "AIVSS_Secondary": "Agent Goal & Instruction Manipulation",
      "ASI_ID": "ASI04",
      "ASI_Title": "Agentic Supply Chain Vulnerabilities",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Controlling technical disclosure prevents attackers from learning system architecture to craft targeted attacks. This protects the supply chain by limiting attack surface knowledge. Goal manipulation is secondary as disclosure enables prompt injection attacks.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "B004",
      "Principle": "Security",
      "RequirementTitle": "B004: Prevent AI endpoint scraping",
      "FullRequirement": "Implement safeguards to prevent probing or scraping of external AI endpoints",
      "Application": "Mandatory",
      "Frequency": "Every 12 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agentic AI Tool Misuse",
      "AIVSS_Secondary": "Agent Access Control Violation",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Preventing endpoint scraping stops misuse of AI APIs as attack tools. Access controls provide additional protection.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "B005",
      "Principle": "Security",
      "RequirementTitle": "B005: Implement real-time input filtering",
      "FullRequirement": "Implement real-time input filtering using automated moderation tools",
      "Application": "Optional",
      "Frequency": "Every 12 months",
      "Capabilities": "Text-generation, Voice-generation, Image-generation",
      "AIVSS_Primary": "Agent Goal & Instruction Manipulation",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Input filtering primarily mitigates prompt injection and goal hijacking attacks. Logging of filtered inputs supports traceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": "Y",
      "Review_Change_Notes": "Manual review: input filtering mitigates prompt injection/goal hijack; documentation/audit secondary."
    },
    {
      "RequirementID": "B006",
      "Principle": "Security",
      "RequirementTitle": "B006: Prevent unauthorized AI agent actions",
      "FullRequirement": "Implement safeguards to limit AI agent system access based on context and declared objectives",
      "Application": "Mandatory",
      "Frequency": "Every 12 months",
      "Capabilities": "Automation",
      "AIVSS_Primary": "Agent Access Control Violation",
      "AIVSS_Secondary": "Agent Orchestration & Multi-Agent Exploitation",
      "ASI_ID": "ASI06",
      "ASI_Title": "Memory & Context Poisoning",
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: context. ASI label inferred: ASI06 (Memory & Context Poisoning). Mapped primarily to AIVSS core risk 'Agent Memory & Context Manipulation' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.5, \"toolUse\": 0.0, \"memoryUse\": 1.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "B007",
      "Principle": "Security",
      "RequirementTitle": "B007: Enforce user access privileges to AI systems",
      "FullRequirement": "Establish and maintain user access controls and admin privileges for AI systems in line with policy",
      "Application": "Mandatory",
      "Frequency": "Every 3 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Access Control Violation",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": "ASI03",
      "ASI_Title": "Identity & Privilege Abuse",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "User access controls and privilege management directly prevent unauthorized access to AI systems. Audit trails support traceability of access changes.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "B008",
      "Principle": "Security",
      "RequirementTitle": "B008: Protect model deployment environment",
      "FullRequirement": "Implement security measures for AI model deployment environments including encryption, access controls and authorization",
      "Application": "Mandatory",
      "Frequency": "Every 12 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Memory & Context Manipulation",
      "AIVSS_Secondary": null,
      "ASI_ID": "ASI03",
      "ASI_Title": "Identity & Privilege Abuse",
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "ASI label inferred: ASI03 (Identity & Privilege Abuse). Mapped primarily to AIVSS core risk 'Agent Access Control Violation' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "B009",
      "Principle": "Security",
      "RequirementTitle": "B009: Limit output over-exposure",
      "FullRequirement": "Implement output limitations and obfuscation techniques to safeguard against information leakage",
      "Application": "Mandatory",
      "Frequency": "Every 12 months",
      "Capabilities": "Text-generation, Voice-generation",
      "AIVSS_Primary": "Agent Memory & Context Manipulation",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Output obfuscation prevents cross-user/session data leakage through agent memory. Audit trails provide traceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": "Y",
      "Review_Change_Notes": "Manual review: output obfuscation to prevent leakage aligns with memory/context (cross-user/session leakage); user notices/audit secondary."
    },
    {
      "RequirementID": "C001",
      "Principle": "Safety",
      "RequirementTitle": "C001: Define AI risk taxonomy",
      "FullRequirement": "Establish a risk taxonomy that categorizes risks within harmful, out-of-scope, and hallucinated outputs, tool calls, and other risks based on application-specific usage",
      "Application": "Mandatory",
      "Frequency": "Every 3 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Goal & Instruction Manipulation",
      "AIVSS_Secondary": "Agentic AI Tool Misuse",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Risk taxonomy defines boundaries for acceptable agent behavior, helping detect goal manipulation. Tool call risks are secondary.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.5, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "C002",
      "Principle": "Safety",
      "RequirementTitle": "C002: Conduct pre-deployment testing",
      "FullRequirement": "Conduct internal testing of AI systems prior to deployment across risk categories for system changes requiring formal review or approval",
      "Application": "Mandatory",
      "Frequency": "Every 12 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Supply Chain & Dependency Risk",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Pre-deployment testing validates system integrity before deployment, addressing supply chain risks. Documentation supports traceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "C003",
      "Principle": "Safety",
      "RequirementTitle": "C003: Prevent harmful outputs",
      "FullRequirement": "Implement safeguards or technical controls to prevent harmful outputs including distressed outputs, angry responses, high-risk advice, offensive content, bias, and deception",
      "Application": "Mandatory",
      "Frequency": "Every 12 months",
      "Capabilities": "Text-generation, Voice-generation, Image-generation",
      "AIVSS_Primary": "Agent Goal & Instruction Manipulation",
      "AIVSS_Secondary": "Insecure Agent Critical Systems Interaction",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Harmful output prevention directly addresses goal manipulation attacks that attempt to elicit dangerous content. Critical systems interaction is secondary.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": "Y",
      "Review_Change_Notes": "Manual review: harmful outputs often induced by prompt/goal manipulation; critical interaction secondary when outputs drive unsafe actions."
    },
    {
      "RequirementID": "C004",
      "Principle": "Safety",
      "RequirementTitle": "C004: Prevent out-of-scope outputs",
      "FullRequirement": "Implement safeguards or technical controls to prevent out-of-scope outputs (e.g. political discussion, healthcare advice)",
      "Application": "Mandatory",
      "Frequency": "Every 12 months",
      "Capabilities": "Text-generation, Voice-generation",
      "AIVSS_Primary": "Agent Goal & Instruction Manipulation",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": "ASI01",
      "ASI_Title": "Agent Goal Hijack",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Preventing out-of-scope outputs constrains agent behavior within defined boundaries, directly addressing goal manipulation where attackers try to elicit unauthorized content.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": "LowConfidence; WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "C005",
      "Principle": "Safety",
      "RequirementTitle": "C005: Prevent customer-defined high risk outputs",
      "FullRequirement": "Implement safeguards or technical controls to prevent additional high risk outputs as defined in risk taxonomy",
      "Application": "Mandatory",
      "Frequency": "Every 12 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Goal & Instruction Manipulation",
      "AIVSS_Secondary": "Agent Cascading Failures",
      "ASI_ID": "ASI01",
      "ASI_Title": "Agent Goal Hijack",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Preventing high-risk outputs as defined in risk taxonomy constrains agent goal execution. Cascading failures are secondary when harmful outputs propagate.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": "LowConfidence; WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "C006",
      "Principle": "Safety",
      "RequirementTitle": "C006: Prevent output vulnerabilities",
      "FullRequirement": "Implement safeguards to prevent security vulnerabilities in outputs from impacting users",
      "Application": "Mandatory",
      "Frequency": "Every 3 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Insecure Agent Critical Systems Interaction",
      "AIVSS_Secondary": "Agent Cascading Failures",
      "ASI_ID": "ASI05",
      "ASI_Title": "Unexpected Code Execution (RCE)",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Preventing security vulnerabilities in outputs (e.g., code injection, XSS) protects critical systems from agent-generated exploits. Cascading failures are secondary.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": "LowConfidence; WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "C007",
      "Principle": "Safety",
      "RequirementTitle": "C007: Flag high risk outputs",
      "FullRequirement": "Implement an alerting system that flags high-risk outputs for human review",
      "Application": "Optional",
      "Frequency": "Every 12 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": "ASI08",
      "ASI_Title": "Cascading Failures",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Flagging high-risk outputs for human review prevents harmful agent outputs from propagating into downstream systems or decisions, directly addressing cascading failures. Audit trails support traceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.5, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "C008",
      "Principle": "Safety",
      "RequirementTitle": "C008: Monitor AI risk categories",
      "FullRequirement": "Implement monitoring of AI systems across risk categories",
      "Application": "Optional",
      "Frequency": "Every 12 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": "Agent Goal & Instruction Manipulation",
      "ASI_ID": "ASI10",
      "ASI_Title": "Rogue Agents",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Monitoring AI systems across risk categories provides visibility into agent behavior, directly addressing untraceability. Detecting behavioral drift also helps identify goal manipulation.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "C009",
      "Principle": "Safety",
      "RequirementTitle": "C009: Enable real-time feedback and intervention",
      "FullRequirement": "Implement mechanisms to enable real-time user feedback collection and intervention mechanisms",
      "Application": "Optional",
      "Frequency": "Every 3 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Cascading Failures",
      "AIVSS_Secondary": "Agent Goal & Instruction Manipulation",
      "ASI_ID": "ASI08",
      "ASI_Title": "Cascading Failures",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Real-time intervention mechanisms (stop/pause/redirect) allow users to halt harmful agent behavior before it cascades. Goal manipulation is secondary as interventions can stop hijacked agents.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.5, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": "Y",
      "Review_Change_Notes": "Manual review: real-time user intervention/stop mechanisms contain cascade/goal-hijack impacts."
    },
    {
      "RequirementID": "C010",
      "Principle": "Safety",
      "RequirementTitle": "C010: Third-party testing for harmful outputs",
      "FullRequirement": "Appoint expert third parties to evaluate system robustness to harmful outputs including distressed outputs, angry responses, high-risk advice, offensive content, bias, and deception at least every 3 months",
      "Application": "Mandatory",
      "Frequency": "Every 3 months",
      "Capabilities": "Text-generation, Voice-generation, Image-generation",
      "AIVSS_Primary": "Agent Goal & Instruction Manipulation",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": "ASI01",
      "ASI_Title": "Agent Goal Hijack",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Third-party testing for harmful outputs validates defenses against goal manipulation attacks that produce dangerous content. Testing records support traceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "C011",
      "Principle": "Safety",
      "RequirementTitle": "C011: Third-party testing for out-of-scope outputs",
      "FullRequirement": "Appoint expert third parties to evaluate system robustness to out-of-scope outputs at least every 3 months (e.g. political discussion, healthcare advice)",
      "Application": "Mandatory",
      "Frequency": "Every 3 months",
      "Capabilities": "Text-generation, Voice-generation",
      "AIVSS_Primary": "Agent Goal & Instruction Manipulation",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": "ASI01",
      "ASI_Title": "Agent Goal Hijack",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Third-party testing for out-of-scope outputs validates defenses against goal manipulation that elicits unauthorized content. Testing records support traceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "C012",
      "Principle": "Safety",
      "RequirementTitle": "C012: Third-party testing for customer-defined risk",
      "FullRequirement": "Appoint expert third-parties to evaluate system robustness to additional high-risk outputs as defined in risk taxonomy at least every 3 months",
      "Application": "Mandatory",
      "Frequency": "Every 3 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Cascading Failures",
      "AIVSS_Secondary": null,
      "ASI_ID": "ASI04",
      "ASI_Title": "Agentic Supply Chain Vulnerabilities",
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: eval, testing. ASI label inferred: ASI04 (Agentic Supply Chain Vulnerabilities). Mapped primarily to AIVSS core risk 'Agent Supply Chain & Dependency Risk' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "D001",
      "Principle": "Reliability",
      "RequirementTitle": "D001: Prevent hallucinated outputs",
      "FullRequirement": "Implement safeguards or technical controls to prevent hallucinated outputs",
      "Application": "Mandatory",
      "Frequency": "Every 12 months",
      "Capabilities": "Text-generation, Voice-generation",
      "AIVSS_Primary": "Agent Cascading Failures",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Hallucination prevention stops false information from propagating through agent chains, preventing cascading failures.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.5, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": "Y",
      "Review_Change_Notes": "Manual review: hallucination prevention reduces hallucination propagation/cascades; citations/traceability secondary."
    },
    {
      "RequirementID": "D002",
      "Principle": "Reliability",
      "RequirementTitle": "D002: Third-party testing for hallucinations",
      "FullRequirement": "Appoint expert third-parties to evaluate hallucinated outputs at least every 3 months",
      "Application": "Mandatory",
      "Frequency": "Every 3 months",
      "Capabilities": "Text-generation, Voice-generation",
      "AIVSS_Primary": "Agent Cascading Failures",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": "ASI08",
      "ASI_Title": "Cascading Failures",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Third-party hallucination testing detects false outputs before they cascade into user decisions. Testing records support traceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.5, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "D003",
      "Principle": "Reliability",
      "RequirementTitle": "D003: Restrict unsafe tool calls",
      "FullRequirement": "Implement safeguards or technical controls to prevent tool calls in AI systems from executing unauthorized actions, accessing restricted information, or making decisions beyond their intended scope",
      "Application": "Mandatory",
      "Frequency": "Every 12 months",
      "Capabilities": "Automation",
      "AIVSS_Primary": "Agentic AI Tool Misuse",
      "AIVSS_Secondary": "Agent Access Control Violation",
      "ASI_ID": "ASI02",
      "ASI_Title": "Tool Abuse",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Safeguards preventing unauthorized tool calls directly address agentic tool misuse. Access controls are secondary.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.5, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "D004",
      "Principle": "Reliability",
      "RequirementTitle": "D004: Third-party testing of tool calls",
      "FullRequirement": "Appoint expert third-parties to evaluate tool calls in AI systems, including executing unauthorized actions, accessing restricted information, or making decisions beyond their intended scope at least every 3 months",
      "Application": "Mandatory",
      "Frequency": "Every 3 months",
      "Capabilities": "Automation",
      "AIVSS_Primary": "Agentic AI Tool Misuse",
      "AIVSS_Secondary": "Agent Access Control Violation",
      "ASI_ID": "ASI02",
      "ASI_Title": "Tool Abuse",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Third-party testing of tool calls validates defenses against unauthorized tool execution. Access control testing is secondary.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.5, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "E001",
      "Principle": "Accountability",
      "RequirementTitle": "E001: AI failure plan for security breaches",
      "FullRequirement": "Document AI failure plan for AI privacy and security breaches assigning accountable owners and establishing notification and remediation with third-party support as needed (e.g. legal, PR, insurers)",
      "Application": "Mandatory",
      "Frequency": "Every 12 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Cascading Failures",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": "ASI08",
      "ASI_Title": "Cascading Failures",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "AI failure plans for security breaches establish response procedures to contain incidents before they cascade. Accountability assignments support traceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.5, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "E002",
      "Principle": "Accountability",
      "RequirementTitle": "E002: AI failure plan for harmful outputs",
      "FullRequirement": "Document AI failure plan for harmful AI outputs that cause significant customer harm assigning accountable owners and establishing remediation with third-party support as needed (e.g. legal, PR, insurers)",
      "Application": "Mandatory",
      "Frequency": "Every 12 months",
      "Capabilities": "Text-generation, Voice-generation, Image-generation",
      "AIVSS_Primary": "Agent Goal & Instruction Manipulation",
      "AIVSS_Secondary": "Agent Cascading Failures",
      "ASI_ID": "ASI01",
      "ASI_Title": "Agent Goal Hijack",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Failure plans for harmful outputs address the consequences of goal manipulation attacks that produce dangerous content. Cascade prevention is secondary.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.5, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "E003",
      "Principle": "Accountability",
      "RequirementTitle": "E003: AI failure plan for hallucinations",
      "FullRequirement": "Document AI failure plan for hallucinated AI outputs that cause substantial customer financial loss assigning accountable owners and establishing remediation with third-party support as needed (e.g. legal, PR, insurers)",
      "Application": "Mandatory",
      "Frequency": "Every 12 months",
      "Capabilities": "Text-generation, Voice-generation",
      "AIVSS_Primary": "Agent Cascading Failures",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": "ASI08",
      "ASI_Title": "Cascading Failures",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Failure plans for hallucinations address scenarios where false agent outputs cascade into financial harm. Accountability supports traceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.5, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.5, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "E004",
      "Principle": "Accountability",
      "RequirementTitle": "E004: Assign accountability",
      "FullRequirement": "Document which AI system changes across the development & deployment lifecycle require formal review or approval, assign a lead accountable for each, and document their approval with supporting evidence",
      "Application": "Mandatory",
      "Frequency": "Every 12 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: approval. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "E005",
      "Principle": "Accountability",
      "RequirementTitle": "E005: Assess cloud vs on-prem processing",
      "FullRequirement": "Establish criteria for selecting cloud provider, and circumstances for on-premises processing considering data sensitivity, regulatory requirements, security controls, and operational needs",
      "Application": "Mandatory",
      "Frequency": "Every 12 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Supply Chain & Dependency Risk",
      "AIVSS_Secondary": "Agent Access Control Violation",
      "ASI_ID": "ASI04",
      "ASI_Title": "Agentic Supply Chain Vulnerabilities",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Cloud vs on-prem decisions directly impact supply chain dependencies and third-party risk exposure. Access control considerations are secondary.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "E006",
      "Principle": "Accountability",
      "RequirementTitle": "E006: Conduct vendor due diligence",
      "FullRequirement": "Establish AI vendor due diligence processes for foundation and upstream model providers covering data handling, PII controls, security and compliance",
      "Application": "Mandatory",
      "Frequency": "Every 12 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Supply Chain & Dependency Risk",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: pii. Mapped primarily to AIVSS core risk 'Agent Supply Chain & Dependency Risk' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Untraceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "E007",
      "Principle": "Accountability",
      "RequirementTitle": "E007: [Retired] Document system change approvals",
      "FullRequirement": "Merged with E004 - see changelog (Q1 2026 update)",
      "Application": "Optional",
      "Frequency": "Every 12 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: approval. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "E008",
      "Principle": "Accountability",
      "RequirementTitle": "E008: Review internal processes",
      "FullRequirement": "Establish regular internal reviews of key processes and document review records and approvals",
      "Application": "Mandatory",
      "Frequency": "Every 12 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: approval. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "E009",
      "Principle": "Accountability",
      "RequirementTitle": "E009: Monitor third-party access",
      "FullRequirement": "Implement systems to monitor third party access",
      "Application": "Optional",
      "Frequency": "Every 12 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Supply Chain & Dependency Risk",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": "ASI04",
      "ASI_Title": "Agentic Supply Chain Vulnerabilities",
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "ASI label inferred: ASI04 (Agentic Supply Chain Vulnerabilities). Mapped primarily to AIVSS core risk 'Agent Supply Chain & Dependency Risk' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Untraceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "E010",
      "Principle": "Accountability",
      "RequirementTitle": "E010: Establish AI acceptable use policy",
      "FullRequirement": "Establish and implement an AI acceptable use policy",
      "Application": "Mandatory",
      "Frequency": "Every 12 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "E011",
      "Principle": "Accountability",
      "RequirementTitle": "E011: Record processing locations",
      "FullRequirement": "Document AI data processing locations",
      "Application": "Mandatory",
      "Frequency": "Every 12 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "E012",
      "Principle": "Accountability",
      "RequirementTitle": "E012: Document regulatory compliance",
      "FullRequirement": "Document applicable AI laws and standards, required data protections, and strategies for compliance",
      "Application": "Mandatory",
      "Frequency": "Every 6 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "E013",
      "Principle": "Accountability",
      "RequirementTitle": "E013: Implement quality management system",
      "FullRequirement": "Establish a quality management system for AI systems proportionate to the size of the organization",
      "Application": "Optional",
      "Frequency": "Every 12 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Supply Chain & Dependency Risk",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: quality management. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "E014",
      "Principle": "Accountability",
      "RequirementTitle": "E014: Share transparency reports",
      "FullRequirement": "Merged with E017 - see changelog (Q1 2026 update)",
      "Application": "Optional",
      "Frequency": "Every 12 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "E015",
      "Principle": "Accountability",
      "RequirementTitle": "E015: Log model activity",
      "FullRequirement": "Maintain logs of AI system processes, actions, and model outputs where permitted to support incident investigation, auditing, and explanation of AI system behavior",
      "Application": "Mandatory",
      "Frequency": "Every 12 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": "ASI10",
      "ASI_Title": "Rogue Agents",
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: audit. ASI label inferred: ASI10 (Rogue Agents). Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.5, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "E016",
      "Principle": "Accountability",
      "RequirementTitle": "E016: Implement AI disclosure mechanisms",
      "FullRequirement": "Implement clear disclosure mechanisms to inform users when they are interacting with AI systems rather than humans",
      "Application": "Mandatory",
      "Frequency": "Every 12 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Identity Impersonation",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: disclosure. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "E017",
      "Principle": "Accountability",
      "RequirementTitle": "E017: Document system transparency policy",
      "FullRequirement": "Establish a system transparency policy and maintain a repository of model cards, datasheets, and interpretability reports for major systems",
      "Application": "Optional",
      "Frequency": "Every 12 months",
      "Capabilities": "Universal",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "RequirementID": "F001",
      "Principle": "Society",
      "RequirementTitle": "F001: Prevent AI cyber misuse",
      "FullRequirement": "Implement or document guardrails to prevent AI-enabled misuse for cyber attacks and exploitation",
      "Application": "Mandatory",
      "Frequency": "Every 12 months",
      "Capabilities": "Text-generation, Automation, Voice-generation",
      "AIVSS_Primary": "Agent Identity Impersonation",
      "AIVSS_Secondary": "Agent Access Control Violation",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Cyber misuse guardrails prevent agents from using tools for malicious purposes. Access controls provide defense in depth.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.5, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": "Y",
      "Review_Change_Notes": "Manual review: cyber misuse guardrails primarily address tool misuse; access control secondary (least privilege/abuse)."
    },
    {
      "RequirementID": "F002",
      "Principle": "Society",
      "RequirementTitle": "F002: Prevent catastrophic misuse",
      "FullRequirement": "Implement or document guardrails to prevent AI-enabled catastrophic system misuse (chemical / bio / radio / nuclear)",
      "Application": "Mandatory",
      "Frequency": "Every 12 months",
      "Capabilities": "Text-generation, Voice-generation, Image-generation",
      "AIVSS_Primary": "Insecure Agent Critical Systems Interaction",
      "AIVSS_Secondary": "Agentic AI Tool Misuse",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Catastrophic misuse prevention focuses on protecting critical systems from agent-induced harm. Tool misuse controls are secondary.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": "Y",
      "Review_Change_Notes": "Manual review: catastrophic misuse tied to critical/physical harm contexts; tool misuse secondary."
    }
  ],
  "controls": [
    {
      "ControlID": "A001.1",
      "RequirementID": "A001",
      "Principle": "Data & Privacy",
      "Category": "Legal Policies",
      "EvidenceTitle": "A001.1 Documentation: Policy for input data ownership, usage and retention",
      "ControlText": "- Defining and communicating input data usage policies. Including specifying how customer data is used for inference and model training, establishing data retention periods, and documenting customer data rights.",
      "TypicalEvidence": "Typically demonstrated by Terms of Service, Privacy Policy or Data Processing Agreement",
      "Control_Function": "Prevent",
      "Control_Type": "Policy",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 1.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "A001.2",
      "RequirementID": "A001",
      "Principle": "Data & Privacy",
      "Category": "Technical Implementation",
      "EvidenceTitle": "A001.2 Config: Data retention implementation",
      "ControlText": "- Implementing technical controls to enforce data retention and deletion policies. For example, automating data deletion based on retention schedules, using secure removal mechanisms, and managing data lifecycles.",
      "TypicalEvidence": "Screenshot of automated deletion implementation or data lifecycle system - may include cron job or scheduled task deleting expired data, deletion script in Python/Bash with retention period logic, data lifecycle management tool configuration (e.g., AWS S3 lifecycle rules, database TTL settings), or deletion audit logs from database or storage system.",
      "Control_Function": "Detect",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: rag, tool, audit, rce. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 1.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "ToolCueMismatch",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "A001.3",
      "RequirementID": "A001",
      "Principle": "Data & Privacy",
      "Category": "Legal Policies",
      "EvidenceTitle": "A001.3 Documentation: Data subject right processes",
      "ControlText": "- Documenting processes for handling end-user data subject rights. For example, handling requests for opt-in/opt-out rights, access, portability, or deletion of input data.",
      "TypicalEvidence": "May be included in DPA, GDPR appendix, External Privacy Policy or similar internal or external policies documenting processes for data handling",
      "Control_Function": "Prevent",
      "Control_Type": "Policy",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": "Agent Memory & Context Manipulation",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Memory & Context Manipulation.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 1.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "A002.1",
      "RequirementID": "A002",
      "Principle": "Data & Privacy",
      "Category": "Legal Policies",
      "EvidenceTitle": "A002.1 Documentation: Output usage and ownership policy",
      "ControlText": "- Establishing output ownership and usage rights policies. For example, specifying customer ownership of AI-generated outputs versus AI inputs, defining permitted uses of outputs (commercial use, redistribution, modification), documenting usage restrictions or limitations, and clarifying how ownership applies to different output types or use cases.\n- Disclosing opt-out and deletion procedures for AI outputs. For example, documenting how customers can opt out of output storage or reuse, explaining deletion request processes, specifying retention periods and data handling practices, and clarifying how customers can control or revoke permissions for their outputs.",
      "TypicalEvidence": "Typically demonstrated by Terms of Service, Data Processing Agreement, Master Service Agreement, Privacy Policy, or AI Addendum. May be a combination of these policies.",
      "Control_Function": "Respond",
      "Control_Type": "Policy",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: rag. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 1.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "A003.1",
      "RequirementID": "A003",
      "Principle": "Data & Privacy",
      "Category": "Technical Implementation",
      "EvidenceTitle": "A003.1 Config: Data collection scoping",
      "ControlText": "- Configuring data collection limits to reduce data and privacy exposure. For example, limiting data collection to task-relevant information based on context, implementing scoping based on user roles or workflow requirements, and avoiding persistent or out-of-scope data access.",
      "TypicalEvidence": "Code implementing data collection restrictions - may include RAG retrieval function with document filtering logic, session scoping configuration limiting data access per session ID, workflow conditional logic gating data collection by stage, permission decorators or middleware checking user roles before data access, or scoping functions rejecting out-of-scope queries with error messages.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Memory & Context Manipulation",
      "AIVSS_Secondary": null,
      "ASI_ID": "ASI06",
      "ASI_Title": "Memory & Context Poisoning",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Detected cues: rag, context, eval. ASI label inferred: ASI06 (Memory & Context Poisoning). Mapped primarily to AIVSS core risk 'Agent Memory & Context Manipulation' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.5, \"toolUse\": 0.0, \"memoryUse\": 1.0, \"dynamicIdentity\": 1.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.5, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "A003.2",
      "RequirementID": "A003",
      "Principle": "Data & Privacy",
      "Category": "Technical Implementation",
      "EvidenceTitle": "A003.2 Config: Alerting system for auth failures",
      "ControlText": "- Deploying monitoring mechanisms. Including ensuring AI systems only perform necessary inference and logging deviations from defined operational scope.",
      "TypicalEvidence": "Screenshot of code showing an alert or error handling system is triggered upon authz check failure, or screenshot of alerting configurations in logging software (e.g. Posthog, Sentry, Datadog, Axiom, or downstream alert in Slack)",
      "Control_Function": "Detect",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": "Agent Memory & Context Manipulation",
      "ASI_ID": "ASI06",
      "ASI_Title": "Memory & Context Poisoning",
      "Bridge_Used": "Y",
      "Confidence": "High",
      "Rationale": "Detected cues: context, logging. ASI label inferred: ASI06 (Memory & Context Poisoning). Mapped primarily to AIVSS core risk 'Agent Memory & Context Manipulation' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Memory & Context Manipulation, Agent Untraceability. ASIAIVSS bridge used to resolve ambiguity via Appendix A alignment.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.5, \"toolUse\": 0.0, \"memoryUse\": 1.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "P1",
      "Review_Checks_Failed": "BridgeUsed; AmbiguousTop2",
      "Review_Change_Flag": "Y",
      "Review_Change_Notes": "Manual review: control is monitoring/logging to ensure limited collection; primary observability/traceability, secondary memory/context."
    },
    {
      "ControlID": "A003.3",
      "RequirementID": "A003",
      "Principle": "Data & Privacy",
      "Category": "Technical Implementation",
      "EvidenceTitle": "A003.3 Config: Authorization system integration",
      "ControlText": "- Integrating with existing authorization systems to align agent access permissions with organizational policies.\n",
      "TypicalEvidence": "Screenshot of code showing authorization checks when context is collected or before tool execution using existing authorization systems (e.g. oAuth, OSO, custom IAM) - should verify that authorization is checked at time of data collection/tool call, not just at initial agent invocation\n",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Access Control Violation",
      "AIVSS_Secondary": "Agentic AI Tool Misuse",
      "ASI_ID": "ASI06",
      "ASI_Title": "Memory & Context Poisoning",
      "Bridge_Used": "Y",
      "Confidence": "High",
      "Rationale": "Detected cues: context, tool, integration, oauth. ASI label inferred: ASI06 (Memory & Context Poisoning). Mapped primarily to AIVSS core risk 'Agent Memory & Context Manipulation' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Memory & Context Manipulation, Agentic AI Tool Misuse. ASIAIVSS bridge used to resolve ambiguity via Appendix A alignment.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.5, \"toolUse\": 1.0, \"memoryUse\": 1.0, \"dynamicIdentity\": 1.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P1",
      "Review_Checks_Failed": "BridgeUsed; AmbiguousTop2; ToolCueMismatch",
      "Review_Change_Flag": "Y",
      "Review_Change_Notes": "Manual review: control is about integrating authorization systems; primary should be access control."
    },
    {
      "ControlID": "A004.1",
      "RequirementID": "A004",
      "Principle": "Data & Privacy",
      "Category": "Technical Implementation",
      "EvidenceTitle": "A004.1 Documentation: User guidance on confidential information",
      "ControlText": "- Providing user guidance on protecting confidential information. For example, instructing employees not to input trade secrets, proprietary code, or confidential business information into AI systems, communicating data handling policies for AI tool usage, or establishing clear guidelines on what information can and cannot be shared with AI agents.",
      "TypicalEvidence": "Policy document, training materials, or user guidelines instructing users on protecting confidential information when using AI systems.",
      "Control_Function": "Prevent",
      "Control_Type": "Policy",
      "AIVSS_Primary": "Agent Access Control Violation",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: tool. Mapped primarily to AIVSS core risk 'Agent Access Control Violation' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Untraceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P1",
      "Review_Checks_Failed": "AmbiguousTop2",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "A004.2",
      "RequirementID": "A004",
      "Principle": "Data & Privacy",
      "Category": "Legal Policies",
      "EvidenceTitle": "A004.2 Documentation: foundational model IP protections",
      "ControlText": "- Leveraging foundation model provider protections. For example, using providers with zero data retention policies, requiring contractual commitments that inputs are not used for training, selecting models with enhanced privacy guarantees for sensitive use cases.",
      "TypicalEvidence": "Provider contracts, terms of service, or documentation showing IP protection commitments. Often found in third party's terms of use/service, DPA or AI Addendum/Schedule",
      "Control_Function": "Prevent",
      "Control_Type": "Policy",
      "AIVSS_Primary": "Agent Supply Chain & Dependency Risk",
      "AIVSS_Secondary": "Agent Access Control Violation",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: rag. Mapped primarily to AIVSS core risk 'Agent Supply Chain & Dependency Risk' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Access Control Violation.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 1.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P1",
      "Review_Checks_Failed": "AmbiguousTop2",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "A004.3",
      "RequirementID": "A004",
      "Principle": "Data & Privacy",
      "Category": "Technical Implementation",
      "EvidenceTitle": "A004.3 Config: IP detection implementation",
      "ControlText": "- Implementing technical controls to detect proprietary information in outputs.",
      "TypicalEvidence": "Screenshot of code or configuration detecting proprietary information patterns in AI outputs - may include labelling proprietary files, filtering rules for internal identifiers/data labels/API keys, scanning logic for trade secret terminology, or rejection demonstrations showing appropriate responses to proprietary requests.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Access Control Violation",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": "ASI03",
      "ASI_Title": "Identity & Privilege Abuse",
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: api, label. ASI label inferred: ASI03 (Identity & Privilege Abuse). Mapped primarily to AIVSS core risk 'Agent Access Control Violation' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Untraceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "A004.4",
      "RequirementID": "A004",
      "Principle": "Data & Privacy",
      "Category": "Technical Implementation",
      "EvidenceTitle": "A004.4 Config: IP disclosure monitoring",
      "ControlText": "- Establishing output monitoring for high-risk IP scenarios. For example, logging AI responses that accessed confidential data sources, implementing human review workflows for outputs flagged as potentially containing sensitive information.",
      "TypicalEvidence": "Logs, audit trails, or review workflow documentation for AI outputs potentially containing sensitive information - may include logs of responses accessing confidential sources, flagged output review queues, or human approval workflows for high-risk disclosures.",
      "Control_Function": "Detect",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": "ASI09",
      "ASI_Title": "Human-Agent Trust Exploitation",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Detected cues: logging, audit, rce, disclosure, approval. ASI label inferred: ASI09 (Human-Agent Trust Exploitation). Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "A005.1",
      "RequirementID": "A005",
      "Principle": "Data & Privacy",
      "Category": "Legal Policies",
      "EvidenceTitle": "A005.1 Documentation: Consent for combined data usage",
      "ControlText": "- Establishing explicit consent and disclosure for combined data usage. For example, informing customers when their data will be combined with competitor data, disclosing data anonymization and abstraction policies, providing opt-out mechanisms.",
      "TypicalEvidence": "Typically demonstrated by Data Processing Agreement or Terms of Service",
      "Control_Function": "Prevent",
      "Control_Type": "Policy",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": "Agent Access Control Violation",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: cross-customer, rce, consent, disclosure. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Access Control Violation.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P1",
      "Review_Checks_Failed": "AmbiguousTop2; AltPrimaryStrongerThanUntraceability",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "A005.2",
      "RequirementID": "A005",
      "Principle": "Data & Privacy",
      "Category": "Technical Implementation",
      "EvidenceTitle": "A005.2 Config: Customer data isolation controls",
      "ControlText": "- Implementing customer data isolation controls. For example, enforcing strict logical and physical separation of customer data, applying tenant-specific encryption, validating data flow boundaries in shared infrastructure, establishing technical barriers between customer datasets during training.",
      "TypicalEvidence": "Screenshot showing app_IDs in database schema, screenshot showing that namespace by appID is used in vector store for RAG or that logical isolation is implemented in an equivalent way, or screenshot of authz check in code verifying appIDs match before returning objects.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Access Control Violation",
      "AIVSS_Secondary": "Agent Memory & Context Manipulation",
      "ASI_ID": "ASI06",
      "ASI_Title": "Memory & Context Poisoning",
      "Bridge_Used": "Y",
      "Confidence": "High",
      "Rationale": "Detected cues: rag, vector, tenant, cross-customer, rce. ASI label inferred: ASI06 (Memory & Context Poisoning). Mapped primarily to AIVSS core risk 'Agent Memory & Context Manipulation' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Memory & Context Manipulation, Insecure Agent Critical Systems Interaction. ASIAIVSS bridge used to resolve ambiguity via Appendix A alignment.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 1.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.5, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "P1",
      "Review_Checks_Failed": "BridgeUsed",
      "Review_Change_Flag": "Y",
      "Review_Change_Notes": "Auto-change: strong heuristic (5.0, gap 2.0) indicates 'Agent Access Control Violation'."
    },
    {
      "ControlID": "A005.3",
      "RequirementID": "A005",
      "Principle": "Data & Privacy",
      "Category": "Technical Implementation",
      "EvidenceTitle": "A005.3 Config: Privacy-enhancing controls",
      "ControlText": "- Implementing specific privacy-enhancing technologies (PETs) to reduce competitive exposure.",
      "TypicalEvidence": "May include tokenization, hashing, or anonymization techniques (robust to prevent re-identification or reversal) making data algorithmic-usable but not human-readable, differential privacy implementation obfuscating individual contributions, federated learning configuration avoiding centralized raw data, or data masking/pseudonymization protecting customer identities.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Access Control Violation",
      "AIVSS_Secondary": "Agent Memory & Context Manipulation",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: token, cross-customer, rce. Mapped primarily to AIVSS core risk 'Agent Access Control Violation' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Memory & Context Manipulation.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 1.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "A006.1",
      "RequirementID": "A006",
      "Principle": "Data & Privacy",
      "Category": "Technical Implementation",
      "EvidenceTitle": "A006.1 Config: PII detection and filtering",
      "ControlText": "- Implementing safeguards to prevent personal data leakage through AI system outputs and logs. For example, filtering prompts and outputs for personal identifiers before storage or display, implementing automated PII detection and redaction in system logs, preventing retention of outputs containing sensitive personal information, or blocking responses that would expose personal identifiers.",
      "TypicalEvidence": "Screenshot of code filtering LLM inputs and/or outputs for personal identifiers - may include keyword checks or regex patterns detecting PII (e.g. names, emails, SSNs, phone numbers), scrubbing functions removing personal data before storage or logging, output filtering blocking responses containing personal identifiers, log redaction configuration removing PII from application or system logs, or structured logging with PII isolation controls.",
      "Control_Function": "Detect",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Access Control Violation",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: rag, logging, pii, personal data. Mapped primarily to AIVSS core risk 'Agent Access Control Violation' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Untraceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 1.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "P1",
      "Review_Checks_Failed": "AmbiguousTop2",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "A006.2",
      "RequirementID": "A006",
      "Principle": "Data & Privacy",
      "Category": "Technical Implementation",
      "EvidenceTitle": "A006.2 Config: PII access controls",
      "ControlText": "- Requiring authentication and authorization for PII access. For example, role-based access controls for PII-containing systems, multi-factor authentication for sensitive data access, or approval-gated access to customer information.",
      "TypicalEvidence": "Screenshot of IAM configuration or user roles list for systems containing PII - e.g. role-based access controls for log aggregation tools or internal dashboards with PII, authentication requirements for PII access, or approval workflow documentation (Jira tickets, approval systems) for internal workforce requests to view customer data.",
      "Control_Function": "Detect",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Access Control Violation",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": "ASI03",
      "ASI_Title": "Identity & Privilege Abuse",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Detected cues: tool, rce, approval, pii, personal data. ASI label inferred: ASI03 (Identity & Privilege Abuse). Mapped primarily to AIVSS core risk 'Agent Access Control Violation' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Untraceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "P1",
      "Review_Checks_Failed": "AmbiguousTop2",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "A006.3",
      "RequirementID": "A006",
      "Principle": "Data & Privacy",
      "Category": "Technical Implementation",
      "EvidenceTitle": "A006.3 Config: DLP system integration",
      "ControlText": "- Integrating with existing data loss prevention (DLP) systems to monitor and block outputs containing personal data in violation of policy.",
      "TypicalEvidence": "Screenshot of output pipeline integrating with DLP system to scan and block PII policy violations - may include DLP integration code scanning AI outputs before delivery to users, DLP configuration rules for PII detection, or logs showing blocked outputs containing personal data.",
      "Control_Function": "Detect",
      "Control_Type": "Policy",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: integration, pii, personal data. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "ToolCueMismatch",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "A007.1",
      "RequirementID": "A007",
      "Principle": "Data & Privacy",
      "Category": "Legal Policies",
      "EvidenceTitle": "A007.1 Documentation: Model provider IP infringement protections",
      "ControlText": "- Documenting foundation model provider IP protections which may serve as primary infringement safeguards. For example, indemnification clauses or copyright/trademark guardrails.",
      "TypicalEvidence": "Foundation model provider contract, terms of service, or data processing agreement showing IP protection commitments including copyright/trademark handling policies, indemnification clauses, liability coverage, and any documented limitations or exclusions. May include vendor questionnaire responses or certification documents addressing IP protections.",
      "Control_Function": "Prevent",
      "Control_Type": "Policy",
      "AIVSS_Primary": "Agent Supply Chain & Dependency Risk",
      "AIVSS_Secondary": null,
      "ASI_ID": "ASI04",
      "ASI_Title": "Agentic Supply Chain Vulnerabilities",
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: rag. ASI label inferred: ASI04 (Agentic Supply Chain Vulnerabilities). Mapped primarily to AIVSS core risk 'Agent Supply Chain & Dependency Risk' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 1.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P1",
      "Review_Checks_Failed": "AmbiguousTop2",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "A007.2",
      "RequirementID": "A007",
      "Principle": "Data & Privacy",
      "Category": "Technical Implementation",
      "EvidenceTitle": "A007.2 Config: IP infringement filtering",
      "ControlText": "- Establishing supplementary content filtering mechanisms where provider protections have gaps or limitations. For example, detecting copyrighted material in outputs, implementing trademark screening.",
      "TypicalEvidence": "Screenshot of code, API configuration, or filtering system showing detection of copyrighted material, trademark screening, or content validation checks applied to AI outputs - this could be pattern matching logic, third-party API integration (e.g. copyright detection services), or custom filtering rules.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Supply Chain & Dependency Risk",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": "ASI04",
      "ASI_Title": "Agentic Supply Chain Vulnerabilities",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "IP infringement filtering addresses risks from training data containing copyrighted content. Content provenance tracking supports traceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": "AmbiguousTop2",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "A007.3",
      "RequirementID": "A007",
      "Principle": "Data & Privacy",
      "Category": "Technical Implementation",
      "EvidenceTitle": "A007.3 Logs: User-facing notices",
      "ControlText": "- Implementing user guidance and guardrails to reduce IP risk. For example, usage policies that explain prohibited content types, user warnings in product, restricting output generation in known infringement domains.\n- Implementing restrictions in AI acceptable use policy.",
      "TypicalEvidence": "Screenshot of user-facing IP risk guidance - may include warning messages when attempting high-risk operations, help center articles about IP infringement guidance, or UI elements explaining prohibited use cases.",
      "Control_Function": "Prevent",
      "Control_Type": "Policy",
      "AIVSS_Primary": "Agent Supply Chain & Dependency Risk",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": "ASI04",
      "ASI_Title": "Agentic Supply Chain Vulnerabilities",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "User-facing IP guidance reduces risk of generating infringing content derived from training data. Notices support traceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": "ASIAlignmentMismatch",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "B001.1",
      "RequirementID": "B001",
      "Principle": "Security",
      "Category": "Third-party Evals",
      "EvidenceTitle": "B001.1 Report: adversarial testing results",
      "ControlText": "- Establishing a taxonomy for adversarial risks. For example, drawing on NIST's AI 100-2e2023 attack classifications and aligning these to system architecture and use cases.\n- Conducting comprehensive adversarial testing at least quarterly. For example, performing structured red-teaming, prompt injection assessments, jailbreaking attempts, adversarial perturbation testing, semantic manipulation, and simulated malicious tool invocations.\n- Maintaining secure testing documentation. For example, recording test cases, methods, outcomes, and system behaviors with restricted access controls, implementing secure storage for sensitive testing materials.\n- Establishing improvement processes based on findings. For example, assigning owners and remediation timelines based on test severity, tracking fixes through risk registers or issue management systems, documenting updates to safeguards and procedures.",
      "TypicalEvidence": "Third-party evaluation report showing adversarial robustness testing - must include risk taxonomy tested, testing methodology and findings, secure documentation practices, and improvement tracking with remediation timelines and documentation.",
      "Control_Function": "Detect",
      "Control_Type": "Process",
      "AIVSS_Primary": "Agent Goal & Instruction Manipulation",
      "AIVSS_Secondary": null,
      "ASI_ID": "ASI01",
      "ASI_Title": "Agent Goal Hijack",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Detected cues: prompt injection, jailbreak, rag, tool, eval, testing. ASI label inferred: ASI01 (Agent Goal Hijack). Mapped primarily to AIVSS core risk 'Agent Goal & Instruction Manipulation' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 1.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "ToolCueMismatch",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "B001.2",
      "RequirementID": "B001",
      "Principle": "Security",
      "Category": "Operational Practices",
      "EvidenceTitle": "B001.2 Documentation: Security program integration",
      "ControlText": "- Aligning adversarial testing with broader security testing programs. For example, integrating AI-specific test cases into broader penetration testing, sharing threat models across red/blue teams, aligning test cycles with security audit and compliance calendars.",
      "TypicalEvidence": "Penetration test reports with AI-specific test cases, shared threat models, and testing calendars, or documentation of broader security program incorporating AI adversarial testing requirements.",
      "Control_Function": "Detect",
      "Control_Type": "Process",
      "AIVSS_Primary": "Agent Goal & Instruction Manipulation",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": "ASI01",
      "ASI_Title": "Agent Goal Hijack",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Security program integration for adversarial testing detects goal manipulation attacks (prompt injection). Testing records support traceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": "ASIAlignmentMismatch; ToolCueMismatch",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "B002.1",
      "RequirementID": "B002",
      "Principle": "Security",
      "Category": "Technical Implementation",
      "EvidenceTitle": "B002.1 Config: Adversarial input detection and alerting",
      "ControlText": "- Establishing detection and alerting. For example, implementing monitoring for prompt injection patterns, jailbreak techniques, adversarial input attempts, and exceeding rate limits, configuring alerts and threat notifications for suspicious activities.",
      "TypicalEvidence": "Screenshot of monitoring system, SIEM, or detection code showing rules and alerts for adversarial inputs - may include prompt injection detection patterns, jailbreak technique signatures, rate limit monitoring with threshold alerts, or notification configurations (Slack, PagerDuty, email)",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Goal & Instruction Manipulation",
      "AIVSS_Secondary": null,
      "ASI_ID": "ASI01",
      "ASI_Title": "Agent Goal Hijack",
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: prompt injection, jailbreak, rate limit. ASI label inferred: ASI01 (Agent Goal Hijack). Mapped primarily to AIVSS core risk 'Agent Goal & Instruction Manipulation' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "B002.2",
      "RequirementID": "B002",
      "Principle": "Security",
      "Category": "Technical Implementation",
      "EvidenceTitle": "B002.2 Logs: Adversarial incident and response",
      "ControlText": "- Implementing incident logging and response procedures. For example, logging suspected adversarial attacks with relevant context, escalating to designated personnel based on severity, and documenting response actions in a centralized system.",
      "TypicalEvidence": "Screenshot of incident management system or logs showing adversarial attack handling - may include log entries with timestamps and user/session context, escalation runbooks defining severity thresholds, or incident tickets in Jira/PagerDuty/ServiceNow documenting response actions and workflows.",
      "Control_Function": "Detect",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": "Agent Goal & Instruction Manipulation; Agent Memory & Context Manipulation",
      "ASI_ID": "ASI06",
      "ASI_Title": "Memory & Context Poisoning",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Incident logging and response for adversarial attacks provides traceability. Detection of goal manipulation and memory poisoning attempts is secondary.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 1.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": "AmbiguousTop2; ASIAlignmentMismatch; MemoryCueMismatch; AltPrimaryStrongerThanUntraceability",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "B002.3",
      "RequirementID": "B002",
      "Principle": "Security",
      "Category": "Technical Implementation",
      "EvidenceTitle": "B002.3 Documentation: Updates to detection config",
      "ControlText": "- Maintaining detection effectiveness through quarterly reviews. For example, updating detection rules based on emerging adversarial techniques, analyzing incident patterns and documenting system improvements.",
      "TypicalEvidence": "Quarterly review documentation showing detection updates - for example, review meeting notes with incident pattern analysis, updated detection rules with version history, or tracking records showing rule improvements (e.g. GitHub/Jira tickets).",
      "Control_Function": "Detect",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Goal & Instruction Manipulation",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": "ASI01",
      "ASI_Title": "Agent Goal Hijack",
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: prompt injection. ASI label inferred: ASI01 (Agent Goal Hijack). Mapped primarily to AIVSS core risk 'Agent Goal & Instruction Manipulation' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Untraceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "B002.4",
      "RequirementID": "B002",
      "Principle": "Security",
      "Category": "Technical Implementation",
      "EvidenceTitle": "B002.4 Config: Pre-processing adversarial detection",
      "ControlText": "- Implementing adversarial input detection prior to AI model processing where feasible. For example, using pre-processing filters to flag likely threats before model processing.",
      "TypicalEvidence": "Screenshot of pre-processing filtering logic or gateway - may include pattern-matching or heuristic code checking inputs before model processing, WAF or API gateway rules blocking adversarial patterns, or IP-based filtering.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Goal & Instruction Manipulation",
      "AIVSS_Secondary": null,
      "ASI_ID": "ASI01",
      "ASI_Title": "Agent Goal Hijack",
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: prompt injection, api. ASI label inferred: ASI01 (Agent Goal Hijack). Mapped primarily to AIVSS core risk 'Agent Goal & Instruction Manipulation' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "WeakSignals; ToolCueMismatch",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "B002.5",
      "RequirementID": "B002",
      "Principle": "Security",
      "Category": "Technical Implementation",
      "EvidenceTitle": "B002.5 Config: AI security alerts",
      "ControlText": "- Integrating adversarial input detection into existing security operations tooling. For example, forwarding flagged inputs to SIEM platforms, correlating detection with authentication and network logs, enabling SOC teams to triage AI-related security events.",
      "TypicalEvidence": "Screenshot of SIEM platform, SOC tooling, or log forwarding configuration showing adversarial detection integration - may include Splunk/Datadog/Elastic SIEM ingesting AI adversarial alerts, correlation rules linking AI events with authentication or network logs, SOC dashboard displaying AI security event triage, or code forwarding flagged inputs to security platforms.",
      "Control_Function": "Detect",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": "ASI01",
      "ASI_Title": "Agent Goal Hijack",
      "Bridge_Used": "Y",
      "Confidence": "Medium",
      "Rationale": "Detected cues: prompt injection, tool, integration. ASI label inferred: ASI01 (Agent Goal Hijack). Mapped primarily to AIVSS core risk 'Agent Goal & Instruction Manipulation' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Goal & Instruction Manipulation. ASIAIVSS bridge used to resolve ambiguity via Appendix A alignment.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "P1",
      "Review_Checks_Failed": "BridgeUsed; ToolCueMismatch",
      "Review_Change_Flag": "Y",
      "Review_Change_Notes": "Auto-change: strong heuristic (4.0, gap 2.0) indicates 'Agent Untraceability'."
    },
    {
      "ControlID": "B003.1",
      "RequirementID": "B003",
      "Principle": "Security",
      "Category": "Operational Practices",
      "EvidenceTitle": "B003.1 Documentation: Technical information disclosure guidelines",
      "ControlText": "- Documenting limitations on technical information release. For example, limiting public disclosure of model architectures, algorithms, training data details, system configurations, and performance metrics, requiring approval before sharing technical specifications or implementation details.\n- Controlling organizational information to balance transparency with security. For example, limiting disclosure of AI team details, development timelines, and other information that could reveal technical capabilities, reviewing public communications for sensitive information.",
      "TypicalEvidence": "Policy document, SOP, or handbook section defining limitations and approval requirements for publicly sharing AI system technical details - may include communication policy limiting disclosure of model architectures or configurations, engineering handbook with approval workflows for technical specifications, or internal procedures controlling release of organizational AI information.\n",
      "Control_Function": "Prevent",
      "Control_Type": "Policy",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": "ASI09",
      "ASI_Title": "Human-Agent Trust Exploitation",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Detected cues: disclosure, approval. ASI label inferred: ASI09 (Human-Agent Trust Exploitation). Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "B003.2",
      "RequirementID": "B003",
      "Principle": "Security",
      "Category": "Operational Practices",
      "EvidenceTitle": "B003.2 Documentation: Public disclosure approval records",
      "ControlText": "- Establishing approval processes. For example, requiring designated review for public content referencing AI capabilities in e.g. publications, presentations, and marketing materials, and documenting approved disclosures with business justification.",
      "TypicalEvidence": "Approval email, ticket, or review documentation for public AI communications - may include approval requests in email or Jira/Slack for blog posts or press releases, marketing review records for AI capability disclosures, or periodic security review logs for public-facing AI content.",
      "Control_Function": "Detect",
      "Control_Type": "Process",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": "ASI09",
      "ASI_Title": "Human-Agent Trust Exploitation",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Detected cues: disclosure, approval. ASI label inferred: ASI09 (Human-Agent Trust Exploitation). Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "B004.1",
      "RequirementID": "B004",
      "Principle": "Security",
      "Category": "Technical Implementation",
      "EvidenceTitle": "B004.1 Config: Anomalous usage detection",
      "ControlText": "- Implementing systems distinguishing between high-volume legitimate usage and adversarial behavior. For example, using behavioral analytics and user profiling to calibrate detection thresholds and prevent false positives against trusted users.",
      "TypicalEvidence": "Screenshot of anomaly detection system or configuration file - may include behavioral analytics dashboard (Datadog, Elastic, Splunk) with user scoring rules, rate limiting configuration with tier-based thresholds (config.yaml, API gateway settings), user allowlists or reputation tables, or code implementing session-based threshold logic.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agentic AI Tool Misuse",
      "AIVSS_Secondary": "Agent Memory & Context Manipulation; Insecure Agent Critical Systems Interaction",
      "ASI_ID": "ASI02",
      "ASI_Title": "Tool Misuse & Exploitation",
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: tool, api, scraping, rate limit. ASI label inferred: ASI02 (Tool Misuse & Exploitation). Mapped primarily to AIVSS core risk 'Agentic AI Tool Misuse' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Memory & Context Manipulation, Insecure Agent Critical Systems Interaction.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "P1",
      "Review_Checks_Failed": "AmbiguousTop2",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "B004.2",
      "RequirementID": "B004",
      "Principle": "Security",
      "Category": "Technical Implementation",
      "EvidenceTitle": "B004.2 Config: Rate limits",
      "ControlText": "- Implementing rate limiting and query restrictions. For example, establishing per-user quotas to prevent model extraction, blocking excessive query patterns, implementing progressive restrictions for suspicious behavior, or using economic disincentives for high-volume usage.",
      "TypicalEvidence": "Screenshot of rate limiting configuration for API endpoints - may include per-user quota settings, query throttling rules, progressive restriction policies, WAF configuration (Cloudflare, AWS WAF, Azure Application Gateway) with blocking rules for excessive patterns, or pricing tier settings implementing usage-based cost increases.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agentic AI Tool Misuse",
      "AIVSS_Secondary": null,
      "ASI_ID": "ASI02",
      "ASI_Title": "Tool Misuse & Exploitation",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Detected cues: tool, api, scraping, rate limit, quota. ASI label inferred: ASI02 (Tool Misuse & Exploitation). Mapped primarily to AIVSS core risk 'Agentic AI Tool Misuse' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "B004.3",
      "RequirementID": "B004",
      "Principle": "Security",
      "Category": "Technical Implementation",
      "EvidenceTitle": "B004.3 Report: External pentest of AI endpoints",
      "ControlText": "- Conducting simulated external attack testing of AI endpoints. For example, performing automated attack simulations, testing endpoint protection effectiveness against high-volume and distributed attacks, and documenting methodologies appropriate to organizational threat profile.",
      "TypicalEvidence": "Third-party penetration test report for AI endpoints including attack simulations tested (e.g. scraping attempts, brute force, reconnaissance), rate limiting and endpoint protection validation, distributed attack testing, test methodology, and findings on protection effectiveness.",
      "Control_Function": "Detect",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Supply Chain & Dependency Risk",
      "AIVSS_Secondary": null,
      "ASI_ID": "ASI04",
      "ASI_Title": "Agentic Supply Chain Vulnerabilities",
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: api, rce, scraping, rate limit, testing. ASI label inferred: ASI04 (Agentic Supply Chain Vulnerabilities). Mapped primarily to AIVSS core risk 'Agent Supply Chain & Dependency Risk' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "B004.4",
      "RequirementID": "B004",
      "Principle": "Security",
      "Category": "Technical Implementation",
      "EvidenceTitle": "B004.4 Documentation: Vulnerability remediation",
      "ControlText": "- Maintaining endpoint security through remediation. For example, tracking identified vulnerabilities, implementing protective measures based on testing outcomes, and regularly updating endpoint defenses and detection thresholds.",
      "TypicalEvidence": "Screenshot of issue tracking system (GitHub, Jira, Linear) showing endpoint vulnerability lifecycle - must include vulnerability identification, remediation proposal, implementation, and production deployment with timestamps and approval records.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Insecure Agent Critical Systems Interaction",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: api, scraping, testing, approval. Mapped primarily to AIVSS core risk 'Insecure Agent Critical Systems Interaction' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Untraceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P1",
      "Review_Checks_Failed": "AmbiguousTop2",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "B005.1",
      "RequirementID": "B005",
      "Principle": "Security",
      "Category": "Technical Implementation",
      "EvidenceTitle": "B005.1 Config: Input filtering",
      "ControlText": "- Integrating automated moderation tools to filter inputs before they reach the foundation model. For example, integrating third-party moderation APIs, implementing custom filtering rules, configuring blocking or warning actions for flagged content, and establishing confidence thresholds based on risk category and severity",
      "TypicalEvidence": "Screenshot of moderation tool integration showing API configuration, filtering rules, action settings (block/warn/modify), and confidence thresholds for different violation categories - this could be screenshots of configuration files, admin dashboard settings, or API integration code.\n\nExample moderation tools: OpenAI Moderation API, Claude content filtering, VirtueAI/Hive/Spectrum Labs",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Goal & Instruction Manipulation",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": "ASI04",
      "ASI_Title": "Agentic Supply Chain Vulnerabilities",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Automated moderation tools detect and block prompt injection attempts, mitigating goal manipulation.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "B005.2",
      "RequirementID": "B005",
      "Principle": "Security",
      "Category": "Technical Implementation",
      "EvidenceTitle": "B005.2 Documentation: Input moderation approach",
      "ControlText": "- Documenting the moderation logic and rationale. For example, explaining chosen moderation tools, threshold justifications, and decision criteria for different risk categories.",
      "TypicalEvidence": "Document explaining moderation approach including tool selection rationale, threshold settings with justifications, action logic for different violation types, and examples of how different input categories are handled.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Goal & Instruction Manipulation",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Documentation of moderation approach supports accountability and refinement of goal manipulation defenses.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": "Y",
      "Review_Change_Notes": "Manual review: documentation of moderation supports accountability; mitigates goal/instruction manipulation."
    },
    {
      "ControlID": "B005.3",
      "RequirementID": "B005",
      "Principle": "Security",
      "Category": "Technical Implementation",
      "EvidenceTitle": "B005.3 Demonstration: Warning for blocked inputs",
      "ControlText": "Providing feedback to users when inputs are blocked.",
      "TypicalEvidence": "Screenshot of user-facing messages or UI flows showing how blocked inputs are communicated to users - this could be error messages, warning dialogs, or alternative suggestions provided when content is filtered.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Goal & Instruction Manipulation",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "User warnings for blocked inputs provide transparency about goal manipulation defense mechanisms.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": "Y",
      "Review_Change_Notes": "Manual review: user-visible blocked-input warnings support transparency/trust; secondary goal/instruction manipulation."
    },
    {
      "ControlID": "B005.4",
      "RequirementID": "B005",
      "Principle": "Security",
      "Category": "Technical Implementation",
      "EvidenceTitle": "B005.4 Logs: Input filtering",
      "ControlText": "- Logging flagged prompts for analysis and refinement of filters, while ensuring compliance with privacy obligations.",
      "TypicalEvidence": "Screenshot of logging system showing how flagged inputs are captured, what metadata is included/excluded for privacy, retention policies, and audit trail - may include privacy documentation explaining logging disclosures to users.",
      "Control_Function": "Detect",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Detected cues: tool, logging, audit, disclosure. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 1.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "B005.5",
      "RequirementID": "B005",
      "Principle": "Security",
      "Category": "Technical Implementation",
      "EvidenceTitle": "B005.5 Documentation: Input filter performance",
      "ControlText": "- Periodically evaluating filter performance and adjusting thresholds accordingly. For example, accuracy, latency, false positives/negatives.",
      "TypicalEvidence": "Report or dashboard showing analysis of filter performance metrics (false positives, false negatives, accuracy, latency) and documented threshold adjustments made based on performance data - should include timestamps and rationale for changes.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Goal & Instruction Manipulation",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Filter performance monitoring ensures prompt injection defenses remain effective over time.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": "Y",
      "Review_Change_Notes": "Manual review: filter performance directly mitigates prompt injection/goal hijack; documentation/metrics secondary."
    },
    {
      "ControlID": "B006.1",
      "RequirementID": "B006",
      "Principle": "Security",
      "Category": "Technical Implementation",
      "EvidenceTitle": "B006.1 Config: Agent service access restrictions",
      "ControlText": "- Implementing technical restrictions that limit agent capabilities to authorized scope. For example, restricting agent access to approved backend services and APIs, enforcing network segmentation or API gateway rules, or implementing service-level authorization preventing access to sensitive systems.",
      "TypicalEvidence": "Screenshot of configuration showing technical limitations on agent backend access - may include API gateway rules restricting accessible services, network policies defining allowed endpoints, service-level authorization configuration, or architecture diagram showing agent isolation boundaries.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Access Control Violation",
      "AIVSS_Secondary": null,
      "ASI_ID": "ASI03",
      "ASI_Title": "Identity & Privilege Abuse",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Detected cues: api. ASI label inferred: ASI03 (Identity & Privilege Abuse). Mapped primarily to AIVSS core risk 'Agent Access Control Violation' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.5, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "B006.2",
      "RequirementID": "B006",
      "Principle": "Security",
      "Category": "Technical Implementation",
      "EvidenceTitle": "B006.2 Config: Agent security monitoring and alerting",
      "ControlText": "- Deploying monitoring and alerting for agent actions that exceed security boundaries. For example, logging all agent service interactions, alerting on access attempts to unauthorized systems or APIs, or anomaly detection flagging unusual connection patterns.",
      "TypicalEvidence": "Screenshot of monitoring configuration tracking agent security-relevant actions - may include logging setup capturing agent service calls and authentication attempts, alert rules for unauthorized system access, security monitoring dashboard showing agent infrastructure interactions, or example logs demonstrating boundary violations are detected.",
      "Control_Function": "Detect",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": "Agent Access Control Violation",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: api, logging. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Access Control Violation.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.5, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "B007.1",
      "RequirementID": "B007",
      "Principle": "Security",
      "Category": "Technical Implementation",
      "EvidenceTitle": "B007.1 Config: User access controls",
      "ControlText": "- Implementing system-level access controls tailored to AI systems. For example, using role-based or attribute-based access to restrict access to model configuration, training datasets, tool-calling capabilities, or prompt logs, based on job function and system sensitivity.\n- Restricting administrative and configuration privileges to authorized personnel. For example, limiting ability to alter system behavior, tools, or models.",
      "TypicalEvidence": "Screenshot of IAM platform, permission files, or admin panel showing role-based or attribute-based access restrictions for AI system resources (model configurations, training datasets, tool-calling capabilities, prompt logs) - may include IAM role assignments, permission policies, or authorization code validating user permissions before accessing sensitive AI components.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Access Control Violation",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": "ASI03",
      "ASI_Title": "Identity & Privilege Abuse",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Detected cues: tool, rce. ASI label inferred: ASI03 (Identity & Privilege Abuse). Mapped primarily to AIVSS core risk 'Agent Access Control Violation' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Untraceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 1.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "B007.2",
      "RequirementID": "B007",
      "Principle": "Security",
      "Category": "Operational Practices",
      "EvidenceTitle": "B007.2 Documentation: Access reviews",
      "ControlText": "- Conducting access reviews and updates at least quarterly. For example, validating access assignments, updating based on policy or role changes,  documenting access changes with AI-specific context (e.g. model access justification, changes to agent capability boundaries, or access to sensitive prompt/response history).",
      "TypicalEvidence": "Quarterly access review documentation - may include access review meeting notes, tracking records of access changes with justifications, or reports documenting role changes and access modifications based on policy updates.",
      "Control_Function": "Detect",
      "Control_Type": "Policy",
      "AIVSS_Primary": "Agent Access Control Violation",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": "ASI06",
      "ASI_Title": "Memory & Context Poisoning",
      "Bridge_Used": "Y",
      "Confidence": "Medium",
      "Rationale": "Detected cues: context, rce. ASI label inferred: ASI06 (Memory & Context Poisoning). Mapped primarily to AIVSS core risk 'Agent Memory & Context Manipulation' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Memory & Context Manipulation, Agent Untraceability. ASIAIVSS bridge used to resolve ambiguity via Appendix A alignment.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.5, \"toolUse\": 0.0, \"memoryUse\": 1.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P1",
      "Review_Checks_Failed": "BridgeUsed; AmbiguousTop2",
      "Review_Change_Flag": "Y",
      "Review_Change_Notes": "Manual review: access reviews enforce privileges; primary access control, secondary audit/traceability."
    },
    {
      "ControlID": "B008.1",
      "RequirementID": "B008",
      "Principle": "Security",
      "Category": "Technical Implementation",
      "EvidenceTitle": "B008.1 Config: Model access controls",
      "ControlText": "- Implementing model access protection. For example, restricting access to production AI models based on job function and operational need, implementing MFA for model system access, maintaining user access reviews appropriate to organizational size.",
      "TypicalEvidence": "Screenshot of IAM configuration, permission settings, or admin panel showing role-based access restrictions for production AI models covering IAM role assignments restricting model access by job function, MFA configuration for model system access, and access review records validating model permissions.",
      "Control_Function": "Detect",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Access Control Violation",
      "AIVSS_Secondary": null,
      "ASI_ID": "ASI03",
      "ASI_Title": "Identity & Privilege Abuse",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "ASI label inferred: ASI03 (Identity & Privilege Abuse). Mapped primarily to AIVSS core risk 'Agent Access Control Violation' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 1.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "B008.2",
      "RequirementID": "B008",
      "Principle": "Security",
      "Category": "Technical Implementation",
      "EvidenceTitle": "B008.2 Config: API deployment security",
      "ControlText": "- Establishing deployment security controls. For example, applying scoped API tokens or signed requests, using TLS for all endpoint traffic, implementing schema validation to protect model APIs from malformed or adversarial input.",
      "TypicalEvidence": "Screenshot of API security configuration for model endpoints - may include scoped API token implementation, TLS/HTTPS certificate configuration for model API traffic, or schema validation code protecting model APIs from malformed or adversarial input.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Access Control Violation",
      "AIVSS_Secondary": null,
      "ASI_ID": "ASI03",
      "ASI_Title": "Identity & Privilege Abuse",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Detected cues: api, token. ASI label inferred: ASI03 (Identity & Privilege Abuse). Mapped primarily to AIVSS core risk 'Agent Access Control Violation' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 1.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "B008.3",
      "RequirementID": "B008",
      "Principle": "Security",
      "Category": "Technical Implementation",
      "EvidenceTitle": "B008.3 Config: Model hosting security",
      "ControlText": "- Securing model hosting environments. For example, using up-to-date and minimal container images, scanning for known vulnerabilities in dependencies and base images, and applying infrastructure-level isolation techniques based on risk level (e.g. container namespaces, VM separation, or dedicated GPU access).",
      "TypicalEvidence": "Screenshot of container configuration or infrastructure setup for model hosting - may include Dockerfile with minimal base images and up-to-date dependencies, vulnerability scanning results from Trivy or Snyk for container images, or infrastructure configuration showing isolation techniques (container namespaces, VM separation, network policies, dedicated GPU allocation).",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Access Control Violation",
      "AIVSS_Secondary": "Insecure Agent Critical Systems Interaction",
      "ASI_ID": "ASI03",
      "ASI_Title": "Identity & Privilege Abuse",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Detected cues: container. ASI label inferred: ASI03 (Identity & Privilege Abuse). Mapped primarily to AIVSS core risk 'Agent Access Control Violation' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Insecure Agent Critical Systems Interaction.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "B008.4",
      "RequirementID": "B008",
      "Principle": "Security",
      "Category": "Technical Implementation",
      "EvidenceTitle": "B008.4 Config: Model integrity verification",
      "ControlText": "- Verifying model integrity before and during deployment. For example, using cryptographic checksums or signed artifacts to detect tampering, scanning model files for malicious payloads.",
      "TypicalEvidence": "Screenshot of deployment pipeline or code implementing model integrity checks - may include cryptographic checksum verification, model artifact signature validation, hash comparison before deployment, model scanning configuration detecting malicious payloads (e.g. Pickle, ONNX) using tools like Cisco's pickle-fuzzer, Trail of Bit's Fickling, or deployment logs recording model version hashes.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Access Control Violation",
      "AIVSS_Secondary": "Agent Untraceability; Agent Supply Chain & Dependency Risk",
      "ASI_ID": "ASI03",
      "ASI_Title": "Identity & Privilege Abuse",
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: tool. ASI label inferred: ASI03 (Identity & Privilege Abuse). Mapped primarily to AIVSS core risk 'Agent Access Control Violation' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Untraceability, Agent Supply Chain & Dependency Risk.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "P1",
      "Review_Checks_Failed": "AmbiguousTop2",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "B009.1",
      "RequirementID": "B009",
      "Principle": "Security",
      "Category": "Technical Implementation",
      "EvidenceTitle": "B009.1 Config: Output volume limits",
      "ControlText": "- Reducing or limiting the number of results shown in outputs to relevant only to balance security and utility. For example, character limits, limits on inference time.",
      "TypicalEvidence": "Screenshot of code or configuration implementing output restrictions - may include character or token limits, inference time limits, result count restrictions, or timeout configurations preventing excessive output. Can be demonstrated by product demo showing system timeout when requesting output exceeding limits.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Access Control Violation",
      "AIVSS_Secondary": "Agent Identity Impersonation",
      "ASI_ID": "ASI03",
      "ASI_Title": "Identity & Privilege Abuse",
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: token. ASI label inferred: ASI03 (Identity & Privilege Abuse). Mapped primarily to AIVSS core risk 'Agent Access Control Violation' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Identity Impersonation.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 1.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "B009.2",
      "RequirementID": "B009",
      "Principle": "Security",
      "Category": "Operational Practices",
      "EvidenceTitle": "B009.2 Demonstration: User output notices",
      "ControlText": "- Providing user-facing notices or documentation about output limitations.",
      "TypicalEvidence": "Screenshot of product interface showing user notices about output limitations - may include messages indicating truncated or suppressed outputs for security or privacy reasons, user documentation explaining limitation policies, or help articles describing output restrictions.",
      "Control_Function": "Prevent",
      "Control_Type": "Process",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": "Agent Memory & Context Manipulation",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "User notices about output limitations provide transparency into agent behavior, supporting traceability. Secondary impact on memory context leakage prevention.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": "Y",
      "Review_Change_Notes": "Manual review: user notices are transparency/traceability; secondary memory/context leakage."
    },
    {
      "ControlID": "B009.3",
      "RequirementID": "B009",
      "Principle": "Security",
      "Category": "Technical Implementation",
      "EvidenceTitle": "B009.3 Config: Output precision controls",
      "ControlText": "- Limiting the fidelity of model outputs in certain use cases. For example, applying output rounding, threshold bands, or obfuscation techniques to reduce the risk of model inversion.",
      "TypicalEvidence": "Screenshot of code implementing output fidelity limitations - may include rounding logic for numerical outputs, threshold bands reducing precision, or obfuscation techniques preventing model inversion, precision-sensitive data disclosure, or adversarial model extraction attacks.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Memory & Context Manipulation",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: disclosure. Mapped primarily to AIVSS core risk 'Agent Identity Impersonation' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Untraceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "WeakSignals",
      "Review_Change_Flag": "Y",
      "Review_Change_Notes": "Manual review: output fidelity limits reduce leakage; transparency secondary."
    },
    {
      "ControlID": "C001.1",
      "RequirementID": "C001",
      "Principle": "Safety",
      "Category": "Operational Practices",
      "EvidenceTitle": "C001.1 Documentation: AI risk taxonomy",
      "ControlText": "- Defining risk categories with severity levels and examples based on industry and deployment context. For example, classifying harmful outputs such as distressed outputs, angry responses, high-risk advice, offensive content, bias, and deception, identifying other high-risk use cases such as safety-critical instructions, legal recommendations, financial advice.\n- Aligning risk taxonomy with external frameworks and standards.\n- Establishing severity grading appropriate to organizational context and risk tolerance. For example, implementing consistent scoring methodology across risk categories, defining thresholds for flagging and human review.",
      "TypicalEvidence": "Internal policy document, risk framework, or taxonomy defining AI risk categories with severity levels and examples specific to deployment context. Example taxonomies to draw upon include NIST AI RMF functions, EU AI Act article 9, ISO42001 controls.",
      "Control_Function": "Detect",
      "Control_Type": "Policy",
      "AIVSS_Primary": "Agent Goal & Instruction Manipulation",
      "AIVSS_Secondary": "Agent Memory & Context Manipulation; Agent Untraceability",
      "ASI_ID": "ASI01",
      "ASI_Title": "Agent Goal Hijack",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Risk taxonomy defines acceptable agent behavior boundaries, helping detect goal manipulation. Memory context and traceability are secondary benefits.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 1.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.5, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": "AmbiguousTop2; ASIAlignmentMismatch",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "C001.2",
      "RequirementID": "C001",
      "Principle": "Safety",
      "Category": "Operational Practices",
      "EvidenceTitle": "C001.2 Documentation: Risk taxonomy reviews",
      "ControlText": "- Maintaining taxonomy currency with documented change management. For example, updating based on emerging threats or incidents.",
      "TypicalEvidence": "Meeting notes, change log, or review documentation showing quarterly reviews of the risk taxonomy. Could include review dates, participants, decisions made (categories added/removed/modified, threshold adjustments), rationale for changes, approvals records, and version history showing taxonomy updates over time with timestamps. Can be standalone or part of broader internal audit/review or change management procedures.",
      "Control_Function": "Detect",
      "Control_Type": "Process",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: tool, audit, change management, approval. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.5, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "C002.1",
      "RequirementID": "C002",
      "Principle": "Safety",
      "Category": "Technical Implementation",
      "EvidenceTitle": "C002.1 Documentation: Pre-deployment test and approval records",
      "ControlText": "- Conducting pre-deployment testing with documented results and identified issues. For example, structured hallucination testing, adversarial prompting, safety unit tests, and scenario-based walkthroughs.\n- Completing risk assessments of identified issues before system deployment. For example, potential impact analysis, mitigation strategies, and residual risk evaluation.\n- Obtaining approval sign-offs from designated accountable. For example, documented rationale for approval decisions and maintained records for review purposes.",
      "TypicalEvidence": "Test results with identified issues and severity ratings, risk assessment with mitigation decisions, and approval sign-offs with rationale - may be combined in deployment gate documentation or provided as separate documents (e.g., test suite outputs from GitHub Actions/pytest, Jira/Linear tickets with risk assessment and approval, staging environment test reports, deployment checklist with sign-offs).",
      "Control_Function": "Detect",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Supply Chain & Dependency Risk",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": "ASI04",
      "ASI_Title": "Agentic Supply Chain Vulnerabilities",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Pre-deployment testing validates system integrity before deployment, addressing supply chain risks. Documentation supports traceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.5, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": "LowConfidence; WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "C002.2",
      "RequirementID": "C002",
      "Principle": "Safety",
      "Category": "Technical Implementation",
      "EvidenceTitle": "C002.2 Config: SDLC integration",
      "ControlText": "- Integrating AI system testing into established software development lifecycle (SDLC) gates. For example, including threat modelling and risk evaluation during design phases, requiring risk evaluation and sign-off at staging or pre-production milestones, aligning with CI/CD or MLOps pipelines, and documenting test artefacts in shared repositories.\"",
      "TypicalEvidence": "CI/CD pipeline configuration or workflow showing AI testing integrated as deployment gate - may include GitHub Actions/Jenkins/GitLab CI config files requiring test passage, pull request templates with testing checklists, or branch protection rules enforcing pre-deployment validation.",
      "Control_Function": "Detect",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Supply Chain & Dependency Risk",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": "ASI04",
      "ASI_Title": "Agentic Supply Chain Vulnerabilities",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "SDLC integration validates AI systems through established gates, addressing supply chain integrity. Documentation supports traceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": "LowConfidence; WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "C002.3",
      "RequirementID": "C002",
      "Principle": "Safety",
      "Category": "Technical Implementation",
      "EvidenceTitle": "C002.3 Documentation: Vulnerability scan results",
      "ControlText": "- Implementing pre-deployment vulnerability scanning of AI artifacts and dependencies. For example, scanning AI models and ML libraries for security vulnerabilities, validating runtime behavior for unsafe operations, and analyzing outputs for harmful content before deployment.",
      "TypicalEvidence": "Screenshot of security scanning tools or CI/CD pipeline showing vulnerability analysis of AI artifacts and dependencies - may include GitHub/GitLab security tab with dependency alerts, Snyk or Dependabot vulnerability findings, pip-audit or safety check terminal output showing CVE scans, model file scanning results, or CI/CD logs showing security scan execution.",
      "Control_Function": "Detect",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Supply Chain & Dependency Risk",
      "AIVSS_Secondary": "Insecure Agent Critical Systems Interaction",
      "ASI_ID": "ASI04",
      "ASI_Title": "Agentic Supply Chain Vulnerabilities",
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Vulnerability scanning of AI artifacts and dependencies addresses supply chain risks. Critical systems interaction is secondary.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": "AmbiguousTop2; ASIAlignmentMismatch",
      "Review_Change_Flag": "Y",
      "Review_Change_Notes": "Manual review: vuln scanning of artifacts/deps is supply chain; critical interaction secondary."
    },
    {
      "ControlID": "C003.1",
      "RequirementID": "C003",
      "Principle": "Safety",
      "Category": "Technical Implementation",
      "EvidenceTitle": "C003.1 Config: Harmful output filtering",
      "ControlText": "- Implementing content filtering for harmful output types. For example, detecting and blocking distressed responses, angry language, offensive content, biased statements, and deceptive information.",
      "TypicalEvidence": "Screenshot of content filtering rules, moderation API configuration, or classifier settings showing detection and blocking logic for harmful output types - may include filtering rules in code, third-party moderation tool configuration (e.g., OpenAI Moderation API, Perspective API), or custom classifier model settings with harm category definitions.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Goal & Instruction Manipulation",
      "AIVSS_Secondary": "Insecure Agent Critical Systems Interaction",
      "ASI_ID": "ASI04",
      "ASI_Title": "Agentic Supply Chain Vulnerabilities",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Technical guardrails block attempts to manipulate agent goals toward generating harmful content.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "C003.2",
      "RequirementID": "C003",
      "Principle": "Safety",
      "Category": "Technical Implementation",
      "EvidenceTitle": "C003.2 Config: Guardrails for high-risk advice",
      "ControlText": "- Implementing guardrails for advice generation. For example, restricting high-risk recommendations in sensitive domains, requiring disclaimers for guidance.",
      "TypicalEvidence": "Screenshot of system prompts, guardrail rules, or domain restrictions showing safety controls on advice generation - may include defensive prompting, domain-specific output restrictions (e.g., medical/legal/financial advice blocklists), or conditional response templates that add warnings for sensitive topics.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Goal & Instruction Manipulation",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Documentation of harmful output categories supports consistent goal manipulation detection.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": "Y",
      "Review_Change_Notes": "Manual review: guardrails constrain malicious/unsafe instruction-following; critical interaction secondary."
    },
    {
      "ControlID": "C003.3",
      "RequirementID": "C003",
      "Principle": "Safety",
      "Category": "Technical Implementation",
      "EvidenceTitle": "C003.3 Config: Guardrails for biased outputs",
      "ControlText": "- Implementing bias detection and mitigation controls. For example, monitoring for discriminatory patterns, implementing fairness checks in outputs.",
      "TypicalEvidence": "Documentation of bias eval results testing for stereotypical responses across demographic attributes, manual review logs documenting bias assessments, or output filtering rules blocking discriminatory patterns - may include automated fairness evaluation tools or bias monitoring dashboards if implemented.",
      "Control_Function": "Detect",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Detected cues: tool, eval, testing. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "C003.4",
      "RequirementID": "C003",
      "Principle": "Safety",
      "Category": "Operational Practices",
      "EvidenceTitle": "C003.4 Documentation: Filtering performance benchmarks",
      "ControlText": "- Evaluating harm mitigation controls using performance metrics.",
      "TypicalEvidence": "Test results, metrics dashboard, or evaluation report showing performance of harm controls - may include false positive/negative rates, coverage analysis of test scenarios, benchmark results against harm datasets (e.g., ToxiGen, RealToxicityPrompts), or confusion matrices showing filtering accuracy across harm categories.",
      "Control_Function": "Detect",
      "Control_Type": "Process",
      "AIVSS_Primary": "Agent Goal & Instruction Manipulation",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Quality evaluation of RAG/grounding techniques validates citation accuracy, addressing goal manipulation that could produce misleading citations.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 1.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": "LowConfidence; WeakSignals",
      "Review_Change_Flag": "Y",
      "Review_Change_Notes": "Manual review: harm-mitigation benchmarks validate guardrails; traceability secondary."
    },
    {
      "ControlID": "C004.1",
      "RequirementID": "C004",
      "Principle": "Safety",
      "Category": "Technical Implementation",
      "EvidenceTitle": "C004.1 Config: out-of-scope guardrails",
      "ControlText": "- Detecting and blocking out-of-scope requests. For example, detecting conversations outside intended use cases, blocking prohibited topics, providing redirection messages when users hit boundaries, and escalating or restricting access for repeated violations.",
      "TypicalEvidence": "Screenshot of blocking rules, defensive prompting, or filtering configuration showing how out-of-scope requests are detected and handled - may include topic blocklists, redirection message templates, escalation rules for repeated attempts, or system prompts defining allowed topics.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Access Control Violation",
      "AIVSS_Secondary": "Agent Identity Impersonation",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: system prompt. Mapped primarily to AIVSS core risk 'Agent Access Control Violation' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Identity Impersonation.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P1",
      "Review_Checks_Failed": "AmbiguousTop2",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "C004.2",
      "RequirementID": "C004",
      "Principle": "Safety",
      "Category": "Technical Implementation",
      "EvidenceTitle": "C004.2 Logs: Out-of-scope attempts",
      "ControlText": "- Tracking out-of-scope violations and updating boundaries. For example, logging boundary violations, adjusting restrictions based on misuse patterns.",
      "TypicalEvidence": "Logs showing out-of-scope attempts with frequency data. May include documentation of boundary updates made in response to violations, monitoring dashboard of flagged requests, change log showing restriction updates with rationale, or incident reports triggering scope adjustments.",
      "Control_Function": "Detect",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Detected cues: logging. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "C004.3",
      "RequirementID": "C004",
      "Principle": "Safety",
      "Category": "Technical Implementation",
      "EvidenceTitle": "C004.3 Demonstration: User guidance on scope",
      "ControlText": "- Providing user guidance on system capabilities and limitations. For example, communicating what the AI system can and cannot do, intended use cases, and topics or requests outside the system's scope.",
      "TypicalEvidence": "Screenshot of user-facing guidance explaining system capabilities and limitations - may include onboarding tooltips or welcome screens, help documentation or FAQs describing intended use, UI warnings when approaching scope boundaries, or published usage guidelines.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Access Control Violation",
      "AIVSS_Secondary": "Agent Identity Impersonation; Agent Untraceability",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Role-based access controls for AI tooling prevent unauthorized access, directly addressing access control violations. Audit trails support traceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": "LowConfidence; WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "C005.1",
      "RequirementID": "C005",
      "Principle": "Safety",
      "Category": "Technical Implementation",
      "EvidenceTitle": "C005.1 Config: Risk detection and response",
      "ControlText": "- Implementing detection and blocking mechanisms aligned with organizational risk taxonomy. For example, deploying filtering based on defined risk categories and severity thresholds.\n- Implementing response actions for detected risks. For example, blocking high-severity outputs, flagging medium-risk content for review, logging violations for monitoring and analysis.",
      "TypicalEvidence": "Screenshot of filtering rules, system configuration, or code showing detection logic mapped to AI risk taxonomy categories and corresponding response actions per severity level - may include risk classifiers with block/flag/log rules, content moderation API configuration defining actions by risk type, or defensive prompting.",
      "Control_Function": "Detect",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: api, logging. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "ToolCueMismatch",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "C005.2",
      "RequirementID": "C005",
      "Principle": "Safety",
      "Category": "Technical Implementation",
      "EvidenceTitle": "C005.2 Documentation: Human review workflows",
      "ControlText": "- Establishing escalation procedures for flagged high-risk content. For example, defining when human review is required and establishing approval workflows for edge cases.",
      "TypicalEvidence": "Documentation or workflow configuration showing human review and escalation procedures for flagged content - may include runbook defining escalation criteria and review SLAs, workflow diagram showing approval process, or ticketing system configuration (Jira, Linear) with content review queues and assignment rules.",
      "Control_Function": "Detect",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Approval workflows with documented decisions provide traceability for access control changes.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": "LowConfidence; WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "C005.3",
      "RequirementID": "C005",
      "Principle": "Safety",
      "Category": "Technical Implementation",
      "EvidenceTitle": "C005.3 Config: Automated response mechanisms",
      "ControlText": "- Implementing automated real-time interventions. For example, blocking or modifying outputs based on severity.",
      "TypicalEvidence": "Screenshot of code or system configuration showing automated response mechanisms - may include logic blocking or modifying outputs based on risk scores, or dynamic warning messages triggered by content flags.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Cascading Failures",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Fallback mechanisms prevent failures from cascading when primary agent components fail.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": "LowConfidence; WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "C006.1",
      "RequirementID": "C006",
      "Principle": "Safety",
      "Category": "Technical Implementation",
      "EvidenceTitle": "C006.1 Config: Output sanitization",
      "ControlText": "- Establishing output sanitization and validation procedures before presenting content to users. For example, encoding or stripping potentially malicious content, validating structured outputs against safe schemas, blocking unsafe URLs, and enforcing secure rendering modes.",
      "TypicalEvidence": "Screenshot of code or configuration implementing output sanitization - may include HTML/JavaScript/shell syntax encoding functions, URL validation or rewriting rules blocking unsafe links, schema validation checking structured outputs (JSON/YAML/XML) against whitelists, CSP header configuration, or template rendering with auto-escaping enabled.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Insecure Agent Critical Systems Interaction",
      "AIVSS_Secondary": null,
      "ASI_ID": "ASI05",
      "ASI_Title": "Unexpected Code Execution (RCE)",
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: api, shell. ASI label inferred: ASI05 (Unexpected Code Execution (RCE)). Mapped primarily to AIVSS core risk 'Insecure Agent Critical Systems Interaction' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "C006.2",
      "RequirementID": "C006",
      "Principle": "Safety",
      "Category": "Technical Implementation",
      "EvidenceTitle": "C006.2 Demonstration: Warning labels for untrusted content",
      "ControlText": "- Implementing security labeling and content handling based on trust level. For example, marking untrusted or third-party content, distinguishing external data from system-generated content, and applying differentiated security controls based on content source.",
      "TypicalEvidence": "Screenshot of UI or code showing trust-based content handling - may include visual indicators marking third-party content (badges, styling, warning icons), metadata tags tracking content source and trust level, or code applying conditional security controls based on content origin (e.g., stricter sanitization for external sources).",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Supply Chain & Dependency Risk",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": "ASI04",
      "ASI_Title": "Agentic Supply Chain Vulnerabilities",
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: rce, label. ASI label inferred: ASI04 (Agentic Supply Chain Vulnerabilities). Mapped primarily to AIVSS core risk 'Agent Supply Chain & Dependency Risk' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Untraceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.5, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "C006.3",
      "RequirementID": "C006",
      "Principle": "Safety",
      "Category": "Technical Implementation",
      "EvidenceTitle": "C006.3 Config: Adversarial output detection",
      "ControlText": "- Detecting advanced output-based attack patterns. For example, identifying prompt injection attempts, model subversion techniques, payloads targeting downstream systems, or obfuscated exploits designed to bypass filters.",
      "TypicalEvidence": "Screenshot of detection rules or monitoring system identifying advanced attack patterns in outputs - may include pattern matching for prompt injection chains or jailbreak tokens, payload signature scanning detecting command injection or SQL queries, or anomaly detection flagging obfuscated exploits bypassing basic filters.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Goal & Instruction Manipulation",
      "AIVSS_Secondary": "Insecure Agent Critical Systems Interaction",
      "ASI_ID": "ASI01",
      "ASI_Title": "Agent Goal Hijack",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Detected cues: prompt injection, jailbreak, token. ASI label inferred: ASI01 (Agent Goal Hijack). Mapped primarily to AIVSS core risk 'Agent Goal & Instruction Manipulation' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Insecure Agent Critical Systems Interaction.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 1.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "P1",
      "Review_Checks_Failed": "AmbiguousTop2",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "C007.1",
      "RequirementID": "C007",
      "Principle": "Safety",
      "Category": "Operational Practices",
      "EvidenceTitle": "C007.1 Documentation: Definition of high-risk recommendations criteria",
      "ControlText": "- Defining high-risk output criteria drawing on risk taxonomy.",
      "TypicalEvidence": "Document or policy defining high-risk outputs requiring human review - should specify criteria for flagging (e.g. financial advice thresholds, medical/legal/safety domains, reputational harm triggers). Can be standalone or included in existing AI risk taxonomy/AI risk policy.",
      "Control_Function": "Detect",
      "Control_Type": "Policy",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "C007.2",
      "RequirementID": "C007",
      "Principle": "Safety",
      "Category": "Technical Implementation",
      "EvidenceTitle": "C007.2 Config: High-risk detection mechanisms",
      "ControlText": "- Implementing automated detection mechanisms for high-risk outputs. For example, using content filtering, risk scoring, or classification models to identify outputs requiring review or flagging.",
      "TypicalEvidence": "Screenshot of detection code, configuration file, or rules engine showing high-risk output filtering - may include keyword lists or regex patterns flagging sensitive topics, scoring logic assigning risk values to recommendations, if/then rules defining high-risk conditions, ML model configuration (e.g., classification thresholds in config.yaml), or API response showing confidence scores with risk thresholds.",
      "Control_Function": "Detect",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Insecure Agent Critical Systems Interaction",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Automated risk detection mechanisms identify threats to critical systems from agent interactions.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": "LowConfidence; WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "C007.3",
      "RequirementID": "C007",
      "Principle": "Safety",
      "Category": "Operational Practices",
      "EvidenceTitle": "C007.3 Documentation: Human review workflows",
      "ControlText": "- Establishing human review workflows for flagged high-risk outputs. For example, assigning reviewers, defining escalation procedures for complex cases, managing review queues with response time tracking, and documenting review decisions.",
      "TypicalEvidence": "Workflow documentation or ticketing system configuration showing human review process for flagged outputs - may include runbook with reviewer assignments and escalation paths, queue management in Jira/Linear/support ticketing with pending review tracking, SLA targets for review response times, or procedure document defining review decision documentation requirements.",
      "Control_Function": "Detect",
      "Control_Type": "Process",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "C008.1",
      "RequirementID": "C008",
      "Principle": "Safety",
      "Category": "Technical Implementation",
      "EvidenceTitle": "C008.1 Logs: AI risk monitoring",
      "ControlText": "- Establishing ongoing monitoring of AI outputs across risk categories. For example, conducting regular evaluations prioritized by risk severity, sampling outputs for review, and tracking system behavior patterns.",
      "TypicalEvidence": "Screenshot of monitoring dashboard, logging system, or evaluation reports showing ongoing AI output tracking - may include output sampling logs with review results, behavior trace logs showing system patterns, prompt-response logging configuration, evaluation schedules prioritized by risk severity, or monitoring metrics dashboard tracking trends over time.",
      "Control_Function": "Detect",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": "ASI10",
      "ASI_Title": "Rogue Agents",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Detected cues: tool, logging, eval. ASI label inferred: ASI10 (Rogue Agents). Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "C008.2",
      "RequirementID": "C008",
      "Principle": "Safety",
      "Category": "Technical Implementation",
      "EvidenceTitle": "C008.2 Documentation: Monitoring findings",
      "ControlText": "- Maintaining documentation. For example, recording identified scenarios with clear examples, updating risk taxonomy based on monitoring findings and incidents.",
      "TypicalEvidence": "Document or change log showing identified risk scenarios with examples - may include incident reports triggering taxonomy changes, risk scenario database with concrete examples, or version history of risk taxonomy showing updates with rationale linked to monitoring findings.",
      "Control_Function": "Detect",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "C008.4",
      "RequirementID": "C008",
      "Principle": "Safety",
      "Category": "Technical Implementation",
      "EvidenceTitle": "C008.4 Config: Security tooling",
      "ControlText": "- Integrating AI output monitoring with existing security tools. For example, forwarding alerts and flagged outputs to SIEM platforms, applying standard logging formats (e.g. JSON, syslog) to support automated threat detection workflows.",
      "TypicalEvidence": "Screenshot of SIEM integration, log forwarding configuration, or security tool settings showing AI monitoring data flowing into existing security infrastructure - may include Splunk/Datadog/Elastic forwarding rules for AI alerts, JSON/syslog format configuration for AI logs, or SIEM dashboard showing AI-related events alongside other security telemetry.",
      "Control_Function": "Detect",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: tool, integration, logging. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "ToolCueMismatch",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "C009.1",
      "RequirementID": "C009",
      "Principle": "Safety",
      "Category": "Technical Implementation",
      "EvidenceTitle": "C009.1 Demonstration: User intervention mechanisms",
      "ControlText": "- Enabling user intervention capabilities. For example, providing mechanisms for users to pause, stop, or redirect system behavior, implementing feedback collection tools for users to report issues or concerns, ensuring technical controls persist across devices and interaction contexts.\n- Ensuring accessibility of feedback and intervention mechanisms. For example, adhering to WCAG 2.1 standards for color contrast, screen reader compatibility, keyboard navigation, and clear messaging for users with disabilities.",
      "TypicalEvidence": "Screenshot, screen recording or voice recording demonstrating intervention controls (stop/pause/redirect buttons, feedback forms, issue reporting mechanisms) with accessibility features integrated (e.g. keyboard navigation, high contrast modes, screen reader labels)",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Cascading Failures",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": "ASI08",
      "ASI_Title": "Cascading Failures",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "User intervention controls (stop/pause/redirect) allow immediate halting of harmful agent behavior before cascading. Audit trails of interventions support traceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.5, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": "Y",
      "Review_Change_Notes": "Manual review: user pause/stop/redirect contains cascades; auditability secondary."
    },
    {
      "ControlID": "C009.2",
      "RequirementID": "C009",
      "Principle": "Safety",
      "Category": "Operational Practices",
      "EvidenceTitle": "C009.2 Documentation: User feedback & intervention reviews",
      "ControlText": "- Reviewing user feedback and intervention logs regularly. For example, evaluating patterns in interventions, adapting communication methods based on user needs and emerging risk considerations.\n- Analyzing collected feedback using structured methodologies. For example, categorizing by risk domain, prioritizing based on frequency and severity,  routing high-impact or repeat issues into product backlog or compliance workflows.",
      "TypicalEvidence": "Logs, reports, or dashboard showing review and analysis of user feedback and intervention patterns - may include feedback summary reports, intervention frequency analysis, categorization by risk domain, documentation of system changes made in response to patterns, or integration with product backlog/compliance workflows.",
      "Control_Function": "Detect",
      "Control_Type": "Process",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Detected cues: integration, eval. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "ToolCueMismatch",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "C010.1",
      "RequirementID": "C010",
      "Principle": "Safety",
      "Category": "Third-party Evals",
      "EvidenceTitle": "C010.1 Report: Harmful output testing",
      "ControlText": "- Appointing qualified third-party assessors. Including selecting assessors with relevant technical capabilities for identified risk areas, maintaining records of assessor qualifications and independence.\n- Conducting regular testing. Including performing assessments of harmful outputs at least every quarter, defining testing scope and methodologies based on risk classifications and industry benchmarks like ToxiGen, coordinating with internal security and testing teams.\n- Maintaining documentation. Including testing scope, results, and remediation actions taken, tracking follow-up activities and resolution timelines.",
      "TypicalEvidence": "Third-party evaluation report showing harmful output testing - must include documentation of assessor qualifications, testing methodology and findings, and improvement tracking with remediation timelines and documentation.",
      "Control_Function": "Prevent",
      "Control_Type": "Process",
      "AIVSS_Primary": "Agent Goal & Instruction Manipulation",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": "ASI01",
      "ASI_Title": "Agent Goal Hijack",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Third-party testing for harmful outputs validates defenses against goal manipulation attacks that produce dangerous content. Testing records support traceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "C011.1",
      "RequirementID": "C011",
      "Principle": "Safety",
      "Category": "Third-party Evals",
      "EvidenceTitle": "C011.1 Report: Out-of-scope output testing",
      "ControlText": "- Appointing qualified third-party assessors. Including selecting assessors with relevant technical capabilities for identified risk areas, maintaining records of assessor qualifications and independence.\n- Conducting regular testing. Including defining testing scope and methodologies based on risk taxonomy and performing assessments of out-of-scope outputs at least every quarter. \n- Maintaining documentation. Including testing scope, results, and remediation actions taken, tracking follow-up activities and resolution timelines.",
      "TypicalEvidence": "Third-party evaluation report showing out-of-scope output testing - must include documentation of assessor qualifications, testing methodology and findings, and improvement tracking with remediation timelines and documentation.",
      "Control_Function": "Prevent",
      "Control_Type": "Process",
      "AIVSS_Primary": "Agent Goal & Instruction Manipulation",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": "ASI01",
      "ASI_Title": "Agent Goal Hijack",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Third-party testing for out-of-scope outputs validates defenses against goal manipulation that elicits unauthorized content. Testing records support traceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "C012.1",
      "RequirementID": "C012",
      "Principle": "Safety",
      "Category": "Third-party Evals",
      "EvidenceTitle": "C012.1 Third-party evaluation report assessing customer-defined risk",
      "ControlText": "- Appointing qualified third-party assessors. Including selecting assessors with relevant technical capabilities for identified risk areas, maintaining records of assessor qualifications and independence.\n- Conducting regular testing. Including defining testing scope and methodologies based on risk taxonomy and performing assessments of high-risk areas at least every quarter.\n- Maintaining documentation. Including testing scope, results, and remediation actions taken, tracking follow-up activities and resolution timelines.",
      "TypicalEvidence": "Third-party evaluation report showing testing of customer-defined risk - must include documentation of assessor qualifications, testing methodology and findings, and improvement tracking with remediation timelines and documentation.",
      "Control_Function": "Prevent",
      "Control_Type": "Process",
      "AIVSS_Primary": "Agent Supply Chain & Dependency Risk",
      "AIVSS_Secondary": "Agent Access Control Violation; Agent Untraceability",
      "ASI_ID": "ASI04",
      "ASI_Title": "Agentic Supply Chain Vulnerabilities",
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: eval, testing. ASI label inferred: ASI04 (Agentic Supply Chain Vulnerabilities). Mapped primarily to AIVSS core risk 'Agent Supply Chain & Dependency Risk' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Access Control Violation, Agent Untraceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P1",
      "Review_Checks_Failed": "AmbiguousTop2",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "D001.1",
      "RequirementID": "D001",
      "Principle": "Reliability",
      "Category": "Technical Implementation",
      "EvidenceTitle": "D001.1 Config: Groundedness filter",
      "ControlText": "- Implementing factual accuracy controls. For example, deploying available fact-checking mechanisms, flagging uncertain or low-confidence responses.",
      "TypicalEvidence": "Screenshot of code or configuration showing groundedness validation - may include filters checking responses against source documents, fact-checking API integration, or logic comparing generated content to retrieved context for factual accuracy.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Cascading Failures",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": "ASI06",
      "ASI_Title": "Memory & Context Poisoning",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "RAG/grounding techniques prevent hallucinated information from cascading through agent workflows.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 1.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.5, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "D001.2",
      "RequirementID": "D001",
      "Principle": "Reliability",
      "Category": "Technical Implementation",
      "EvidenceTitle": "D001.2 Demonstration: User-facing citations & source attributions",
      "ControlText": "- Establishing information source validation. For example, requiring citations for factual claims, implementing source reliability checks.",
      "TypicalEvidence": "Screenshot of UI or output format showing citations and source attributions provided to users - may include inline citations, source links, reference lists, or attribution labels identifying where information originated.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Cascading Failures",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Citation requirements enable tracing of information sources, supporting cascade prevention and audit.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.5, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": "Y",
      "Review_Change_Notes": "Manual review: citations/source validation provide traceability and reduce cascade of hallucinated inputs."
    },
    {
      "ControlID": "D001.3",
      "RequirementID": "D001",
      "Principle": "Reliability",
      "Category": "Technical Implementation",
      "EvidenceTitle": "D001.3 Demonstration: User-facing uncertainty labels",
      "ControlText": "- Maintaining uncertainty communication. For example, displaying confidence levels, providing appropriate disclaimers for generated information.",
      "TypicalEvidence": "Screenshot of UI or output format showing confidence levels, uncertainty disclaimers, or warnings for generated information - may include confidence score displays, low-certainty warnings, or standard disclaimers about potential inaccuracies.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": "Agent Cascading Failures",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Output labeling provides transparency into AI-generated content, supporting traceability. Prevention of cascading errors is secondary.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.5, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": "LowConfidence; WeakSignals",
      "Review_Change_Flag": "Y",
      "Review_Change_Notes": "Manual review: uncertainty labels improve transparency and reduce downstream cascade risk."
    },
    {
      "ControlID": "D002.1",
      "RequirementID": "D002",
      "Principle": "Reliability",
      "Category": "Third-party Evals",
      "EvidenceTitle": "D002.1 Report: Hallucination testing results",
      "ControlText": "- Appointing qualified third-party assessors. Including selecting assessors with relevant technical capabilities for identified risk areas, maintaining records of assessor qualifications and independence.\n- Conducting regular testing. Including defining testing scope and methodologies based on risk taxonomy and performing assessments at least every quarter.\n- Maintaining documentation. Including testing scope, results, and remediation actions taken, tracking follow-up activities and resolution timelines.",
      "TypicalEvidence": "Third-party evaluation report showing hallucination testing - must include risk taxonomy tested, testing methodology and findings, and improvement tracking with remediation timelines and documentation.",
      "Control_Function": "Prevent",
      "Control_Type": "Process",
      "AIVSS_Primary": "Agent Cascading Failures",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": "ASI08",
      "ASI_Title": "Cascading Failures",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Third-party hallucination testing detects false outputs before they cascade into user decisions. Testing records support traceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.5, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "D003.1",
      "RequirementID": "D003",
      "Principle": "Reliability",
      "Category": "Technical Implementation",
      "EvidenceTitle": "D003.1 Config: Tool authorization & validation",
      "ControlText": "- Implementing function call validation and authorization. For example, restricting tool access to approved functions, validating parameters before execution.",
      "TypicalEvidence": "Screenshot of code or configuration showing function allowlists, parameter validation logic, or authz checks before tool execution - may include tool permission schemas, input validation functions, or access control lists restricting available tools per agent/user.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Access Control Violation",
      "AIVSS_Secondary": "Agentic AI Tool Misuse",
      "ASI_ID": "ASI03",
      "ASI_Title": "Identity & Privilege Abuse",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Detected cues: tool. ASI label inferred: ASI03 (Identity & Privilege Abuse). Mapped primarily to AIVSS core risk 'Agent Access Control Violation' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agentic AI Tool Misuse.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.5, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 1.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "P1",
      "Review_Checks_Failed": "AmbiguousTop2",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "D003.2",
      "RequirementID": "D003",
      "Principle": "Reliability",
      "Category": "Technical Implementation",
      "EvidenceTitle": "D003.2 Config: Rate limits for tools",
      "ControlText": "- Enforcing rate limits and transaction caps for autonomous tool use.",
      "TypicalEvidence": "Screenshot of code or configuration showing rate limits and transaction caps on tool usage - may include per-tool usage quotas, time-windowed limits, or circuit breakers preventing excessive autonomous tool calls.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agentic AI Tool Misuse",
      "AIVSS_Secondary": "Agent Access Control Violation",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Rate limits and transaction caps prevent excessive tool calls, directly addressing tool misuse. Access controls are secondary.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.5, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": "LowConfidence; WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "D003.3",
      "RequirementID": "D003",
      "Principle": "Reliability",
      "Category": "Technical Implementation",
      "EvidenceTitle": "D003.3 Config: Tool call log",
      "ControlText": "- Establishing execution monitoring and logging. For example, tracking all tool calls, monitoring for unauthorized access attempts or scope violations.",
      "TypicalEvidence": "Screenshot of logging configuration, monitoring dashboard, or audit logs showing tracked tool calls - may include tool execution logs with timestamps and parameters, alerts for unauthorized access attempts, or monitoring system flagging scope violations.",
      "Control_Function": "Detect",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agentic AI Tool Misuse",
      "AIVSS_Secondary": "Agent Untraceability; Agent Access Control Violation",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: tool, logging, audit. Mapped primarily to AIVSS core risk 'Agentic AI Tool Misuse' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Untraceability, Agent Access Control Violation.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.5, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "P1",
      "Review_Checks_Failed": "AmbiguousTop2",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "D003.4",
      "RequirementID": "D003",
      "Principle": "Reliability",
      "Category": "Operational Practices",
      "EvidenceTitle": "D003.4 Config: Human-approval workflows",
      "ControlText": "- Requiring human approval for sensitive tool operations. For example, requiring human confirmation before executing high-risk actions, implementing approval workflows for operations beyond autonomous boundaries.",
      "TypicalEvidence": "Screenshot of approval workflow, code requiring human confirmation, or ticketing system for sensitive tool operations",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agentic AI Tool Misuse",
      "AIVSS_Secondary": "Agent Access Control Violation; Agent Untraceability",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Human approval workflows for sensitive tool operations prevent misuse of high-risk capabilities. Access controls and audit trails are secondary.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.5, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": "LowConfidence; WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "D003.5",
      "RequirementID": "D003",
      "Principle": "Reliability",
      "Category": "Operational Practices",
      "EvidenceTitle": "D003.5 Documentation: tool call log reviews",
      "ControlText": "- Reviewing patterns of AI tool usage. For example, identifying anomalies, updating tool permissions, and retiring unused or high-risk functions during scheduled evaluations.",
      "TypicalEvidence": "Reports or documentation showing periodic review of tool usage patterns, permission updates, and function retirement decisions - may include usage analytics identifying anomalies, change logs showing permission adjustments, or records of deprecated/retired tools with rationale.",
      "Control_Function": "Detect",
      "Control_Type": "Process",
      "AIVSS_Primary": "Agentic AI Tool Misuse",
      "AIVSS_Secondary": "Agent Access Control Violation; Agent Untraceability",
      "ASI_ID": "ASI03",
      "ASI_Title": "Identity & Privilege Abuse",
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Reviewing patterns of AI tool usage identifies anomalies and informs permission updates, addressing tool misuse. Access control and audit are secondary.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.5, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 1.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": "AmbiguousTop2; ASIAlignmentMismatch; ToolCueMismatch",
      "Review_Change_Flag": "Y",
      "Review_Change_Notes": "Manual review: tool-usage review/retiring unsafe functions is tool-misuse mitigation; secondary access control + audit."
    },
    {
      "ControlID": "D004.1",
      "RequirementID": "D004",
      "Principle": "Reliability",
      "Category": "Third-party Evals",
      "EvidenceTitle": "D004.1 Report: Tool call testing",
      "ControlText": "- Appointing qualified third-party assessors. Including selecting assessors with relevant technical capabilities for identified risk areas, maintaining records of assessor qualifications and independence.\n- Conducting regular testing. Including defining testing scope and methodologies based on risk taxonomy and performing assessments of tool calls at least every quarter.\n- Maintaining documentation. Including testing scope, results, and remediation actions taken, tracking follow-up activities and resolution timelines.",
      "TypicalEvidence": "Third-party evaluation report showing tool call testing - must include risk taxonomy tested, testing methodology and findings, and improvement tracking with remediation timelines and documentation.",
      "Control_Function": "Prevent",
      "Control_Type": "Process",
      "AIVSS_Primary": "Agentic AI Tool Misuse",
      "AIVSS_Secondary": "Agent Supply Chain & Dependency Risk",
      "ASI_ID": "ASI04",
      "ASI_Title": "Agentic Supply Chain Vulnerabilities",
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Pre-deployment testing of new tool integrations validates behavior, preventing tool misuse. Supply chain validation is secondary.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.5, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": "AmbiguousTop2; ASIAlignmentMismatch",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E001.1",
      "RequirementID": "E001",
      "Principle": "Accountability",
      "Category": "Operational Practices",
      "EvidenceTitle": "E001.1 Documentation: AI failure plan for security breaches",
      "ControlText": "- Assigning a breach response lead from existing staff. For example, IT manager, security officer, or designated executive with authority to engage external counsel and specialists as needed.\n- Defining breach notification procedures. For example, customer communications, regulatory reporting requirements, and vendor notifications based on applicable privacy laws.\n- Implementing security remediation measures. For example, system freeze capabilities, vulnerability fixes, access control updates, and coordination with external security consultants when internal expertise is insufficient.\n- Establishing evidence collection requirements with guidance on preserving evidence for potential legal review. For example, system logs, user activity records, and basic documentation.",
      "TypicalEvidence": "Can be standalone document or integrated in existing incident response procedures/policies",
      "Control_Function": "Respond",
      "Control_Type": "Process",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": "ASI04",
      "ASI_Title": "Agentic Supply Chain Vulnerabilities",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "AI failure plans for security breaches establish response procedures and accountability, supporting traceability and cascade prevention.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.5, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": "AmbiguousTop2; ASIAlignmentMismatch",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E002.1",
      "RequirementID": "E002",
      "Principle": "Accountability",
      "Category": "Operational Practices",
      "EvidenceTitle": "E002.1 Documentation: AI failure plan for harmful outputs",
      "ControlText": "- Implementing customer communication protocols. For example, disclosure procedures, explanation of corrective actions, and follow-up commitments with executive approval for significant incidents.\n- Establishing immediate mitigation steps with designated staff responsibilities. For example, system freeze capabilities, output suppression, customer notification, and system adjustments.",
      "TypicalEvidence": "Can be standalone document or integrated in existing incident response procedures/policies",
      "Control_Function": "Respond",
      "Control_Type": "Process",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": "Agent Supply Chain & Dependency Risk",
      "ASI_ID": "ASI04",
      "ASI_Title": "Agentic Supply Chain Vulnerabilities",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Customer communication and mitigation protocols for harmful outputs establish accountability and response procedures, supporting traceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.5, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": "WeakSignals; ASIAlignmentMismatch",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E002.2",
      "RequirementID": "E002",
      "Principle": "Accountability",
      "Category": "Operational Practices",
      "EvidenceTitle": "E002.2 Documentation: Additional harmful output failure procedures",
      "ControlText": "- Defining harmful output categories with reference to risk taxonomy. For example, discriminatory content, offensive material, inappropriate recommendations, ideally with concrete examples.\n- Coordinating external support engagement. For example,  legal counsel consultation, PR support, and insurance claim procedures.",
      "TypicalEvidence": "May include harmful output category definitions referenced to risk taxonomy, external support contact list (legal counsel, PR firms, insurance providers), support engagement procedures or runbooks, or escalation criteria for involving external parties.",
      "Control_Function": "Prevent",
      "Control_Type": "Process",
      "AIVSS_Primary": "Agent Goal & Instruction Manipulation",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": "ASI01",
      "ASI_Title": "Agent Goal Hijack",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Defining harmful output categories addresses consequences of goal manipulation that produces dangerous content. Traceability is secondary.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.5, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": "WeakSignals; ASIAlignmentMismatch",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E003.1",
      "RequirementID": "E003",
      "Principle": "Accountability",
      "Category": "Operational Practices",
      "EvidenceTitle": "E003.1 Documentation: AI failure plan for hallucinations",
      "ControlText": "- Establishing compensation assessment procedures. For example, loss evaluation methods, settlement approaches, and payment authorization levels with appropriate approval requirements.\n- Implementing remediation measures. For example, system freeze capabilities, model adjustments, output validation improvements, customer notification, and enhanced monitoring.",
      "TypicalEvidence": "Can be standalone document or integrated in existing incident response procedures/policies",
      "Control_Function": "Respond",
      "Control_Type": "Process",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": "Agent Supply Chain & Dependency Risk",
      "ASI_ID": "ASI03",
      "ASI_Title": "Identity & Privilege Abuse",
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Compensation assessment and remediation procedures for hallucinations address cascading financial harm. Traceability is secondary.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.5, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.5, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": "AmbiguousTop2; ASIAlignmentMismatch",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E003.2",
      "RequirementID": "E003",
      "Principle": "Accountability",
      "Category": "Operational Practices",
      "EvidenceTitle": "E003.2 Documentation: Additional hallucination failure procedures",
      "ControlText": "- Defining hallucination incident types. \n- Coordinating potential external support. For example, legal consultation for significant claims, financial review when needed, and insurance coverage activation.",
      "TypicalEvidence": "May include hallucination incident categories (e.g. factual errors, incorrect recommendations), external support contact list (legal counsel, financial reviewers, insurance providers), support engagement procedures, or escalation criteria for involving external parties.",
      "Control_Function": "Detect",
      "Control_Type": "Process",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": "Agent Supply Chain & Dependency Risk",
      "ASI_ID": "ASI04",
      "ASI_Title": "Agentic Supply Chain Vulnerabilities",
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Defining hallucination incident types and coordinating external support addresses cascading financial harm from false outputs. Traceability is secondary.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 1.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.5, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.5, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": "WeakSignals; ASIAlignmentMismatch",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E004.1",
      "RequirementID": "E004",
      "Principle": "Accountability",
      "Category": "Operational Practices",
      "EvidenceTitle": "E004.1 Documentation: Change approval policy and records",
      "ControlText": "- Defining AI system changes requiring approval including model selection, material changes to the meta prompt, adding / removing guardrails, changes to end-user workflow, other changes that drive material. For example, +/-10% performance on evals.\n- Assigning an accountable lead as approver for each of these changes. Can follow a RACI structure to formalize roles of those consulted and informed.",
      "TypicalEvidence": "Documentation or policy defining which AI system changes require approval with assigned accountable leads, and approval records showing sign-offs with supporting evidence. Can be a change management policy, overview table in e.g. Notion, approval logs from Jira/Linear/GitHub, or deployment gate documentation.",
      "Control_Function": "Prevent",
      "Control_Type": "Policy",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Detected cues: eval, change management, approval. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E004.2",
      "RequirementID": "E004",
      "Principle": "Accountability",
      "Category": "Technical Implementation",
      "EvidenceTitle": "E004.2 Config: Code signing implementation",
      "ControlText": "- Implementing code signing and verification processes for AI models, libraries, and deployment artefacts to ensure only digitally signed components are approved for production use.",
      "TypicalEvidence": "Screenshot of code signing configuration, CI/CD pipeline requiring signed artifacts, or verification process for AI components - may include model signing process, signature verification in deployment pipeline, artifact registry showing signed models/libraries, or policy enforcement blocking unsigned components from production.",
      "Control_Function": "Prevent",
      "Control_Type": "Policy",
      "AIVSS_Primary": "Agent Supply Chain & Dependency Risk",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": "ASI04",
      "ASI_Title": "Agentic Supply Chain Vulnerabilities",
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Code signing and verification for AI components addresses supply chain integrity by ensuring only approved artifacts reach production. Traceability is secondary.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": "AmbiguousTop2; ASIAlignmentMismatch; AltPrimaryStrongerThanUntraceability",
      "Review_Change_Flag": "Y",
      "Review_Change_Notes": "Manual review: code signing/verification is supply-chain integrity; audit/traceability secondary."
    },
    {
      "ControlID": "E005.1",
      "RequirementID": "E005",
      "Principle": "Accountability",
      "Category": "Operational Practices",
      "EvidenceTitle": "E005.1 Documentation: Deployment decisions",
      "ControlText": "- Conducting deployment risk assessments. For example, evaluating data sensitivity, regulatory compliance requirements, IP protection needs, and security controls for cloud vs. on-premises AI processing.\n- Documenting decision criteria and rationale. For example, establishing clear selection factors, maintaining records of deployment choices with business justification.\n- Reviewing deployment decisions when requirements change. For example, reassessing choices when data sensitivity, regulations, or threat landscape evolves.",
      "TypicalEvidence": "Risk assessment and decision record evaluating cloud vs. on-premises factors (e.g. data sensitivity, regulatory requirements, security controls) with documented criteria and rationale - may include deployment decision memos, risk assessment reports, and records of periodic reviews when requirements changed.",
      "Control_Function": "Detect",
      "Control_Type": "Process",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: eval. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E006.1",
      "RequirementID": "E006",
      "Principle": "Accountability",
      "Category": "Operational Practices",
      "EvidenceTitle": "E006.1 Documentation: Vendor due diligence",
      "ControlText": "- Defining assessment criteria for foundational or upstream AI models. For example, data handling and ownership practices, PII controls, security measures, compliance status, open-source.\n- Conducting documented assessments. For example, scoring results, verification activities such as certifications reviewed and references contacted, and approval decisions. \n- Maintaining assessment records with sufficient detail for audit purposes and retaining due diligence evidence before vendor approval.",
      "TypicalEvidence": "Vendor assessment records showing evaluation criteria, scoring results, verification activities, approval decisions with accountable leads, and retained evidence supporting the assessment. May include vendor questionnaires, security reviews, compliance documentation, or due diligence reports.",
      "Control_Function": "Detect",
      "Control_Type": "Process",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Detected cues: audit, rce, eval, approval, pii. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E007.1",
      "RequirementID": "E007",
      "Principle": "Accountability",
      "Category": null,
      "EvidenceTitle": "E007.1 Retired",
      "ControlText": "- Documenting formal review and approval decisions for changes defined in E004: Assign accountability.",
      "TypicalEvidence": "This requirement was merged into E004 at the Q1, 2026 standard update. See aiuc-1.com/changelog for more information",
      "Control_Function": "Detect",
      "Control_Type": "Process",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: approval. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E008.1",
      "RequirementID": "E008",
      "Principle": "Accountability",
      "Category": "Operational Practices",
      "EvidenceTitle": "E008.1 Documentation: Internal review",
      "ControlText": "- Reviewing decision processes every quarter including AI system changes, foundational model selection, security assessment.\n- Maintaining a centralized repository of decision records and internal review of these record. For example, supporting evidence reviewed, remediation plans.\n- Documenting and tracking remediation of any risks identified.int",
      "TypicalEvidence": "Centralized repository, policy, or tickets showing quarterly internal reviews - e.g. review meeting notes or calendars, decision logs in Jira/Notion/Confluence, risk registers with remediation status, threat modelling outcomes, or audit trails of review activities.",
      "Control_Function": "Detect",
      "Control_Type": "Policy",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Detected cues: audit, approval. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.5, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E008.2",
      "RequirementID": "E008",
      "Principle": "Accountability",
      "Category": "Operational Practices",
      "EvidenceTitle": "E008.2 Documentation: External feedback integration",
      "ControlText": "- Collecting and implementing external feedback on AI systems. For example, system risks, new threat patterns, new mitigation strategies.",
      "TypicalEvidence": "Documentation showing external feedback collected and implemented - may include external security advisories reviewed, threat intelligence integrated, third-party recommendations adopted, or records of external input incorporated into system improvements.",
      "Control_Function": "Prevent",
      "Control_Type": "Process",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": "Agent Supply Chain & Dependency Risk",
      "ASI_ID": "ASI04",
      "ASI_Title": "Agentic Supply Chain Vulnerabilities",
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Collecting and implementing external feedback helps identify emerging risks and improves system security, supporting supply chain resilience. Traceability is secondary.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": "AmbiguousTop2; ASIAlignmentMismatch; ToolCueMismatch; AltPrimaryStrongerThanUntraceability",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E009.1",
      "RequirementID": "E009",
      "Principle": "Accountability",
      "Category": "Technical Implementation",
      "EvidenceTitle": "E009.1 Config: Third-party access monitoring",
      "ControlText": "- Configuring logging for third-party interactions. For example, capturing API connections, user access sessions, data exchanges, and service integrations.\n- Capturing access metadata. For example, user identification, authentication timestamps, accessed resources, session duration, origin IP addresses, and resource usage patterns.",
      "TypicalEvidence": "Screenshot of logging system or SIEM configuration showing third-party interactions being monitored with captured metadata - may include cloud logging interface (Google Cloud Logging, AWS CloudWatch, Azure Monitor) showing logged API requests with timestamps/IPs/user agents, access logs capturing authentication events and resource access, or SIEM dashboard displaying third-party connection monitoring with relevant metadata fields.",
      "Control_Function": "Detect",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": "ASI04",
      "ASI_Title": "Agentic Supply Chain Vulnerabilities",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Third-party access monitoring provides visibility into external interactions with AI systems, directly supporting traceability and supply chain visibility.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": "AmbiguousTop2; ASIAlignmentMismatch; ToolCueMismatch",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E010.1",
      "RequirementID": "E010",
      "Principle": "Accountability",
      "Category": "Legal Policies",
      "EvidenceTitle": "E010.1 Documentation: AI acceptable use policy",
      "ControlText": "- Defining prohibited AI usage for end-users. For example, jailbreak attempts, malicious prompt injection, unauthorized data extraction, generation of harmful content, and misuse of customer data.",
      "TypicalEvidence": "Policy document defining acceptable and/or prohibited AI usage - can be standalone document or parts of, e.g., terms of service",
      "Control_Function": "Prevent",
      "Control_Type": "Policy",
      "AIVSS_Primary": "Agent Goal & Instruction Manipulation",
      "AIVSS_Secondary": null,
      "ASI_ID": "ASI01",
      "ASI_Title": "Agent Goal Hijack",
      "Bridge_Used": "Y",
      "Confidence": "High",
      "Rationale": "Detected cues: prompt injection, jailbreak. ASI label inferred: ASI01 (Agent Goal Hijack). Mapped primarily to AIVSS core risk 'Agent Goal & Instruction Manipulation' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Goal & Instruction Manipulation. ASIAIVSS bridge used to resolve ambiguity via Appendix A alignment.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P1",
      "Review_Checks_Failed": "BridgeUsed; AmbiguousTop2",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E010.2",
      "RequirementID": "E010",
      "Principle": "Accountability",
      "Category": "Technical Implementation",
      "EvidenceTitle": "E010.2 Config: AUP violation detection",
      "ControlText": "- Implementing detection and monitoring tools. For example, prompt analysis, output filtering, usage pattern anomalies, and suspicious access attempts.",
      "TypicalEvidence": "Screenshot of code, configuration, or monitoring system detecting acceptable use policy violations - may include prompt analysis logic, output filtering rules, anomaly detection for usage patterns, or alerting on suspicious access attempts.",
      "Control_Function": "Prevent",
      "Control_Type": "Policy",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: tool. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E010.3",
      "RequirementID": "E010",
      "Principle": "Accountability",
      "Category": "Technical Implementation",
      "EvidenceTitle": "E010.3 Demonstration: User notification for AUP breaches",
      "ControlText": "- Implementing user feedback when policy is breached. For example, showing alerts or error messages when inputs violate acceptable use.",
      "TypicalEvidence": "Screenshot of user-facing alerts or error messages displayed when acceptable use policy is violated - may include in-product warning messages, blocked request notifications, or error screens explaining policy violations.",
      "Control_Function": "Prevent",
      "Control_Type": "Policy",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E010.4",
      "RequirementID": "E010",
      "Principle": "Accountability",
      "Category": "Technical Implementation",
      "EvidenceTitle": "E010.4 Documentation: Guardrails enforcing acceptable use",
      "ControlText": "- Real-time monitoring, blocking, or alerting capabilities.\n- Maintaining logging and tracking systems. For example, incident creation, violation tracking with case assignment and resolution documentation.\n- Conducting regular effectiveness reviews. For example, quarterly analysis of violation trends, tool performance assessment, policy updates based on emerging threats, and user training adjustments.",
      "TypicalEvidence": "Documentation or screenshots showing additional AUP enforcement mechanisms - may include real-time blocking/alerting systems, violation tracking logs with incident management, effectiveness review reports analyzing violation trends and policy updates, or training materials addressing emerging misuse patterns.",
      "Control_Function": "Detect",
      "Control_Type": "Policy",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Detected cues: tool, logging, rce. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "ToolCueMismatch",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E011.1",
      "RequirementID": "E011",
      "Principle": "Accountability",
      "Category": "Operational Practices",
      "EvidenceTitle": "E011.1 Documentation: AI processing locations",
      "ControlText": "- Maintaining AI infrastructure location documentation. For example, geographic locations of foundation model processing locations and inference endpoint regions, documenting third-party AI service provider data handling locations.\n- Reviewing and updating documentation regularly.",
      "TypicalEvidence": "Subprocessor list showing third-party AI provider locations, infrastructure documentation listing cloud regions and inference endpoints, or data flow diagram with geographic processing locations and version history or review dates.",
      "Control_Function": "Detect",
      "Control_Type": "Process",
      "AIVSS_Primary": "Agent Supply Chain & Dependency Risk",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": "ASI04",
      "ASI_Title": "Agentic Supply Chain Vulnerabilities",
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "ASI label inferred: ASI04 (Agentic Supply Chain Vulnerabilities). Mapped primarily to AIVSS core risk 'Agent Supply Chain & Dependency Risk' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Untraceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P1",
      "Review_Checks_Failed": "AmbiguousTop2",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E011.2",
      "RequirementID": "E011",
      "Principle": "Accountability",
      "Category": "Legal Policies",
      "EvidenceTitle": "E011.2 Documentation: Data transfer compliance",
      "ControlText": "- Implementing transfer compliance procedures. For example, assessing data transfer requirements for AI training data and inference processing, maintaining approved transfer mechanisms for foundation model providers and AI infrastructure, mitigating transfer risk for cross-border AI model training.",
      "TypicalEvidence": "Demonstrated by DPA, data transfer impact assessments, approved transfer mechanism documentation (Standard Contractual Clauses, adequacy decisions), cross-border data flow approvals for AI training/inference, or risk assessments for international AI processing.",
      "Control_Function": "Prevent",
      "Control_Type": "Policy",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: approval. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E012.1",
      "RequirementID": "E012",
      "Principle": "Accountability",
      "Category": "Legal Policies",
      "EvidenceTitle": "E012.1 Documentation: Regulatory compliance reviews",
      "ControlText": "- Identifying relevant regulations. For example, data protection laws. For example, GDPR, CCPA, sector-specific requirements, emerging AI standards. For example, EU AI Act.\n- Documenting compliance procedures and strategies appropriate for company size and operations.\n- Reviewing the repository every 6 months and when additional requirements may be triggered. For example, regulations change or business operations expand into new jurisdictions.",
      "TypicalEvidence": "Compliance register, assessment memo or review tickets (e.g. in Notion), or policy listing applicable regulations with compliance strategies - should include review dates or version history showing periodic updates.",
      "Control_Function": "Detect",
      "Control_Type": "Policy",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E013.1",
      "RequirementID": "E013",
      "Principle": "Accountability",
      "Category": "Operational Practices",
      "EvidenceTitle": "E013.1 Documentation: Quality objectives and risk management",
      "ControlText": "- Defining quality objectives, metrics, and risk management approach for AI systems. For example, establishing performance targets, safety thresholds, risk assessment methodologies, and measurement processes appropriate to system risk level.",
      "TypicalEvidence": "Documentation showing quality objectives, metrics, and risk management approach - may include quality metrics dashboard or reports, risk assessment documentation for AI systems, performance targets and safety thresholds, or measurement methodologies defining how quality is evaluated.",
      "Control_Function": "Detect",
      "Control_Type": "Process",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: eval, quality management. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E013.2",
      "RequirementID": "E013",
      "Principle": "Accountability",
      "Category": "Operational Practices",
      "EvidenceTitle": "E013.2 Documentation: Change management procedures",
      "ControlText": "- Establishing change management, approval processes, and documentation standards. For example, defining review and approval requirements for AI system changes, assigning accountability for quality decisions, documenting design and development procedures.",
      "TypicalEvidence": "Documentation showing change management and approval processes - may include change approval workflows or procedures, RACI matrix assigning accountability for quality decisions, design and development procedure documents, or documentation standards and templates for AI systems. May be fulfilled by evidence submitted to E004: Assign accountability.",
      "Control_Function": "Detect",
      "Control_Type": "Process",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: change management, approval, quality management. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E013.3",
      "RequirementID": "E013",
      "Principle": "Accountability",
      "Category": "Technical Implementation",
      "EvidenceTitle": "E013.3 Config: Issue tracking and monitoring",
      "ControlText": "- Implementing defect tracking, continuous improvement, and post-market monitoring. For example, maintaining issue tracking systems, conducting root cause analysis, documenting corrective actions, establishing post-market monitoring processes.",
      "TypicalEvidence": "Screenshot of issue tracking system or monitoring records - may include issue tracker (Jira, Linear, GitHub) with defects and corrective actions, root cause analysis reports, post-market monitoring logs or dashboards, or continuous improvement documentation showing lessons learned.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Detected cues: tool, quality management. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E013.4",
      "RequirementID": "E013",
      "Principle": "Accountability",
      "Category": "Operational Practices",
      "EvidenceTitle": "E013.4 Documentation: Data management procedures",
      "ControlText": "- Establishing data management and record-keeping systems. For example, documenting data governance procedures, maintaining technical documentation, implementing record retention policies for model training data and system outputs.",
      "TypicalEvidence": "Documentation showing data management and record-keeping practices - may include data governance policies, technical documentation standards, record retention procedures, or data lineage tracking systems for training data and system outputs.",
      "Control_Function": "Prevent",
      "Control_Type": "Process",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Detected cues: quality management. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 1.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E013.5",
      "RequirementID": "E013",
      "Principle": "Accountability",
      "Category": "Operational Practices",
      "EvidenceTitle": "E013.5 Documentation: Stakeholder communication procedures",
      "ControlText": "- Documenting communication procedures with regulatory authorities and stakeholders. For example, establishing protocols for regulatory reporting, stakeholder notifications for incidents, and procedures for authority interactions.",
      "TypicalEvidence": "Procedures document or communication protocols - may include incident reporting templates or protocols to regulatory authorities, stakeholder notification procedures for serious incidents, guidelines for interacting with competent authorities or notified bodies, or escalation procedures for regulatory communications.",
      "Control_Function": "Prevent",
      "Control_Type": "Process",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: quality management. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E014.1",
      "RequirementID": "E014",
      "Principle": "Accountability",
      "Category": null,
      "EvidenceTitle": "E014.1 Not applicable",
      "ControlText": "This requirement was merged into E017 at the Q1, 2026 standard update. See aiuc-1.com/changelog for more information",
      "TypicalEvidence": "Not applicable",
      "Control_Function": "Prevent",
      "Control_Type": "Process",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E015.1",
      "RequirementID": "E015",
      "Principle": "Accountability",
      "Category": "Technical Implementation",
      "EvidenceTitle": "E015.1 Config: Logging implementation",
      "ControlText": "- Capturing system activity details to support incident investigation and behavior explanation. For example, logging inputs, processing steps, outputs, and metadata for AI systems.",
      "TypicalEvidence": "Screenshot of logging code or configuration showing what system activity is captured - may include code logging inputs and outputs, logging configuration file specifying what to log, or example log entries showing captured information (timestamps, inputs, outputs, user actions).",
      "Control_Function": "Detect",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": "ASI10",
      "ASI_Title": "Rogue Agents",
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: logging, audit. ASI label inferred: ASI10 (Rogue Agents). Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.5, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E015.2",
      "RequirementID": "E015",
      "Principle": "Accountability",
      "Category": "Technical Implementation",
      "EvidenceTitle": "E015.2 Config: Log storage",
      "ControlText": "- Implementing log storage with appropriate retention periods, access controls, and data sanitation to support auditing and incident response.",
      "TypicalEvidence": "Screenshot of log storage system showing retention policies, access controls and sanitation practices - may include log management platform (Datadog, Splunk, CloudWatch) with retention period settings and PII-masking, access control configuration showing who can view logs, or storage settings with automatic deletion rules.",
      "Control_Function": "Respond",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": "ASI10",
      "ASI_Title": "Rogue Agents",
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: rag, tool, audit, pii. ASI label inferred: ASI10 (Rogue Agents). Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 1.0, \"memoryUse\": 1.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.5, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "P1",
      "Review_Checks_Failed": "AmbiguousTop2; AltPrimaryStrongerThanUntraceability",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E015.3",
      "RequirementID": "E015",
      "Principle": "Accountability",
      "Category": "Technical Implementation",
      "EvidenceTitle": "E015.3 Config: Log integrity protection",
      "ControlText": "- Implementing technical controls to ensure logs are tamper-evident and independently verifiable. For example, ensuring that captured records cannot be modified or deleted after creation, ensuring sequence integrity so that gaps, omissions, and reordering are detectable during incident investigation or audit.",
      "TypicalEvidence": "Screenshot or documentation of log immutability controls - for example, write-once-read-many (WORM) storage configuration, cryptographic hashing of log entries, append-only database settings, or third-party log management platform features.",
      "Control_Function": "Detect",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": "ASI04",
      "ASI_Title": "Agentic Supply Chain Vulnerabilities",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Log integrity protection ensures audit trails cannot be tampered with, directly supporting traceability and forensic investigation.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 1.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.5, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": "ASIAlignmentMismatch",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E016.1",
      "RequirementID": "E016",
      "Principle": "Accountability",
      "Category": "Technical Implementation",
      "EvidenceTitle": "E016.1 Demonstration: Text AI disclosure",
      "ControlText": "- Implementing AI disclosure for text-based interactions. For example, displaying clear notices when users interact with AI chatbots, virtual assistants, or automated messaging systems.",
      "TypicalEvidence": "Screenshot of text-based AI disclosure - may include chatbot interface with \"You're chatting with AI\" notice, messaging system showing AI agent identifier, website chat widget with AI disclosure banner, or automated email/SMS with AI generation notice.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: disclosure. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.5, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.5, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E016.2",
      "RequirementID": "E016",
      "Principle": "Accountability",
      "Category": "Technical Implementation",
      "EvidenceTitle": "E016.2 Demonstration: Voice AI disclosure",
      "ControlText": "- Implementing AI disclosure for voice-based interactions. For example, providing audio notifications at the beginning of voice calls or interactions.",
      "TypicalEvidence": "Screenshot of transcript or audio recording of voice AI disclosure.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": "Agent Identity Impersonation",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: disclosure. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Identity Impersonation.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E016.3",
      "RequirementID": "E016",
      "Principle": "Accountability",
      "Category": "Technical Implementation",
      "EvidenceTitle": "E016.3 Demonstration: Labelling AI-generated content",
      "ControlText": "- Labelling AI-generated media and documents in a machine-readable and detectable format. For example, marking AI-generated images, videos, audio, or documents with metadata, watermarks, or labels indicating artificial generation.",
      "TypicalEvidence": "Screenshot showing AI generation labeling implementation - may include Content Credentials or C2PA metadata embedded in files, visible watermarking system with AI generation marks, classifier output detecting and flagging AI-generated content, or metadata tagging system marking files as artificially generated.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: credential, disclosure, label. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 1.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E016.4",
      "RequirementID": "E016",
      "Principle": "Accountability",
      "Category": "Technical Implementation",
      "EvidenceTitle": "E016.4 Demonstration: Automation AI disclosure",
      "ControlText": "- Disclosing when autonomous AI agents or automated workflows are performing actions. For example, notifying users when AI systems are making decisions, processing requests, or executing tasks without human oversight.",
      "TypicalEvidence": "Screenshot showing AI automation disclosure in product - may include \"Powered by AI\" or \"AI Agent\" labels in interface, workflow dashboard displaying AI-automated tasks, status indicators showing \"AI is handling this\" or \"Automated by AI,\" or notification messages stating \"AI agent completed your request.\"",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": "ASI09",
      "ASI_Title": "Human-Agent Trust Exploitation",
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: disclosure, label. ASI label inferred: ASI09 (Human-Agent Trust Exploitation). Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.5, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E016.5",
      "RequirementID": "E016",
      "Principle": "Accountability",
      "Category": "Technical Implementation",
      "EvidenceTitle": "E016.5 Demonstration: System response to AI inquiry",
      "ControlText": "- Establishing reactive disclosure capabilities when users ask if they are interacting with AI.",
      "TypicalEvidence": "Screenshot of chatbot or voice agent transcript responding to \"Are you AI?\"",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": "Agent Identity Impersonation",
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: disclosure. Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated. Secondary impact likely also reduces: Agent Identity Impersonation.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.5, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P2",
      "Review_Checks_Failed": "WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E017.1",
      "RequirementID": "E017",
      "Principle": "Accountability",
      "Category": "Legal Policies",
      "EvidenceTitle": "E017.1 Documentation: Transparency policy",
      "ControlText": "- Establishing a transparency policy defining documentation requirements for major AI systems. For example, specifying required documentation elements, establishing documentation standards.",
      "TypicalEvidence": "Policy document defining transparency documentation requirements - may include criteria for systems requiring documentation, required documentation elements (capabilities, limitations, use cases, risks), or documentation standards and templates.",
      "Control_Function": "Prevent",
      "Control_Type": "Policy",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E017.2",
      "RequirementID": "E017",
      "Principle": "Accountability",
      "Category": "Technical Implementation",
      "EvidenceTitle": "E017.2 Documentation: Model cards and system documentation",
      "ControlText": "- Creating transparency documentation for major AI systems. For example, documenting system characteristics, data provenance, and model behavior for systems meeting documentation criteria.",
      "TypicalEvidence": "Transparency documentation artifacts - may include model card (PDF, Markdown, web page) with system capabilities/limitations/intended use, datasheet showing training data sources and characteristics, interpretability report with example inputs/outputs and decision explanations, technical documentation describing model architecture and performance metrics, or an AI Bill of Materials (may follow CycloneDX or SPDX 3.0)",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": "ASI10",
      "ASI_Title": "Rogue Agents",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Detected cues: rce, provenance. ASI label inferred: ASI10 (Rogue Agents). Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.5, \"contextualAwareness\": 0.5, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "E017.3",
      "RequirementID": "E017",
      "Principle": "Accountability",
      "Category": "Operational Practices",
      "EvidenceTitle": "E017.3 Documentation: Transparency report sharing policy",
      "ControlText": "- Defining policies for sharing transparency documentation with external stakeholders. For example, establishing when reports are shared, specifying recipient categories, determining what information is disclosed to each stakeholder type.\n- Documenting sharing procedures including approval workflows, version control, and distribution tracking. For example, establishing approval requirements before external sharing, maintaining version control of shared documents, tracking which stakeholders received which versions.",
      "TypicalEvidence": "Policy document defining transparency sharing practices - may include sharing triggers, recipient categories with disclosure levels (regulators, customers, affected parties, public), or matrix mapping stakeholder types to shared documentation (model cards, datasheets, performance reports, incident summaries).",
      "Control_Function": "Prevent",
      "Control_Type": "Policy",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": "ASI09",
      "ASI_Title": "Human-Agent Trust Exploitation",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Detected cues: disclosure, approval. ASI label inferred: ASI09 (Human-Agent Trust Exploitation). Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "F001.1",
      "RequirementID": "F001",
      "Principle": "Society",
      "Category": "Legal Policies",
      "EvidenceTitle": "F001.1 Documentation: Foundation model cyber capabilities",
      "ControlText": "- Results of testing from foundation model developer on offensive cyber capabilities and mitigations.",
      "TypicalEvidence": "Provider model cards, cybersecurity assessment reports from model developers, or foundation model documentation describing offensive cyber capabilities and mitigations",
      "Control_Function": "Detect",
      "Control_Type": "Policy",
      "AIVSS_Primary": "Agent Supply Chain & Dependency Risk",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: testing. Mapped primarily to AIVSS core risk 'Agent Supply Chain & Dependency Risk' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.5, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P1",
      "Review_Checks_Failed": "AmbiguousTop2",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "F001.2",
      "RequirementID": "F001",
      "Principle": "Society",
      "Category": "Technical Implementation",
      "EvidenceTitle": "F001.2 Config: Cyber use detection",
      "ControlText": "- Implementing malicious use detection and blocking. For example, deploying available content filtering to detect requests for malicious code generation, attack planning, and vulnerability exploitation guidance, configuring automated blocking of cyber attack assistance requests, maintaining databases of prohibited use patterns.",
      "TypicalEvidence": "Content filtering rules blocking cyber attack requests, keyword or pattern matching detecting malicious code generation attempts, automated blocking configuration for exploit development queries, or prohibited use pattern database.",
      "Control_Function": "Prevent",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agentic AI Tool Misuse",
      "AIVSS_Secondary": "Agent Untraceability",
      "ASI_ID": "ASI02",
      "ASI_Title": "Tool Abuse",
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Malicious use detection prevents agents from being used for cyber attacks. Logging of blocked requests supports traceability.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.5, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.5, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": "WeakSignals",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "F002.1",
      "RequirementID": "F002",
      "Principle": "Society",
      "Category": "Legal Policies",
      "EvidenceTitle": "F002.1 Documentation: Foundation model CBRN capabilities",
      "ControlText": "- Results of testing from foundation model developer on CBRN capabilities and mitigations.",
      "TypicalEvidence": "List of foundation models used with CBRN capability information - may include provider model cards with CBRN assessments, weapons of mass destruction risk evaluations from model developers, or other documentation describing CBRN-related capabilities and mitigations.",
      "Control_Function": "Prevent",
      "Control_Type": "Policy",
      "AIVSS_Primary": "Agent Supply Chain & Dependency Risk",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "Medium",
      "Rationale": "Detected cues: eval, testing. Mapped primarily to AIVSS core risk 'Agent Supply Chain & Dependency Risk' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.0}",
      "Review_Priority": "P1",
      "Review_Checks_Failed": "AmbiguousTop2",
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    },
    {
      "ControlID": "F002.2",
      "RequirementID": "F002",
      "Principle": "Society",
      "Category": "Technical Implementation",
      "EvidenceTitle": "F002.2 Config: Catastrophic misuse monitoring",
      "ControlText": "- Establishing catastrophic misuse monitoring. For example, monitoring AI system interactions for patterns indicating weapons development or mass harm intent, implementing real-time alerting for detected catastrophic misuse attempts, documenting suspicious queries and system responses.",
      "TypicalEvidence": "Monitoring dashboard or alert configuration for catastrophic misuse patterns - may include usage monitoring flagging CBRN-related queries, alert rules for weapons development patterns, logs of detected and blocked catastrophic misuse attempts, or incident records documenting suspicious CBRN-related interactions.",
      "Control_Function": "Detect",
      "Control_Type": "Technical",
      "AIVSS_Primary": "Agent Untraceability",
      "AIVSS_Secondary": null,
      "ASI_ID": null,
      "ASI_Title": null,
      "Bridge_Used": "N",
      "Confidence": "High",
      "Rationale": "Mapped primarily to AIVSS core risk 'Agent Untraceability' as the most direct agentic failure mode mitigated.",
      "AARS_Factors_Suggested": "{\"autonomyOfAction\": 0.0, \"toolUse\": 0.0, \"memoryUse\": 0.0, \"dynamicIdentity\": 0.0, \"multiAgentInteractions\": 0.0, \"nonDeterminism\": 0.0, \"selfModification\": 0.0, \"goalDrivenPlanning\": 0.0, \"contextualAwareness\": 0.0, \"opacityAndReflexivity\": 0.5}",
      "Review_Priority": "OK",
      "Review_Checks_Failed": null,
      "Review_Change_Flag": null,
      "Review_Change_Notes": null
    }
  ]
}